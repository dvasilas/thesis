
Chapter: design space

% It is important to note that the framework of read and write path computations does not include the memory and storage
% costs associated with maintaining derived state.

% In the era of global-scale services, data sets are becoming increasingly geo-distributed, as the services that produce them run in multiple locations.
% This happens because organizations spread data storage and processing across multiple data centers to improve user-perceived latency
% and ensure availability and regulatory compliance,
% and between
% on-premise and cloud infrastructure to increase reliability and decrease costs.



% Let's consider a database that maintains 3 replicas of its dataset in the 3 different data centers, and
% uses a \textit{strongly-consistent} design:
% It favors strong consistency, but exposes high
% It uses a leader based replication scheme; writes are submitted to the data center where the leader replica is placed,
% while reads can be served from any data center.
% Let's consider the design options involved in maintaining a secondary index in this scenario.

% One approach is to maintain an index replica for each data replica.
% This means that the read path only involves local communication: each user connects to data center located geographically
% closest to them, and index lookups are served from the local index.
% However, the write path involves sending each update to the base data to index replicas in all other data centers.
% Synchronous index maintenance in this case means that there is significant overhead to write operations.
% As a result, this design choice is more suitable for data that are rarely updated but often read, for example identity
% and access management (IAM) data.

% Alternatively, index replicas can be maintained asynchronously:
% This approach does impact write operations, but means that the time window in which an index replica ...
% This approach is more suitable for case in which low write operation are latency-sensitive and it is acceptable to
% read potentially stale data.
% \todo{cite social networks?}

% A third approach is to maintain a single index replica, located on the same data center as the base data leader replica.
% This entails that cross-site communication is needed for the write path, but it is needed for index lookups from other
% data centers.

% \medskip

% Eventual consistency


% \medskip
% gep-partitioned tables


% ...






% --- --- --- --- --- --- ---
% users can be served from data centers geographically close to them.
% replicas are distributed across  (for geographical proximity to users or for availability)
% If you have users around the world, you might want to have servers at various locations worldwide so that each
% Fault tolerance/high availability
% If the servers are spread across multiple geographically distributed data centers,
% for example in order to tolerate an entire data center going offline
% In a geographically distributed deployment ()
% Placing data geographically close to users, so that users can interact with it faster
% multiple copies
% read and write path potentially cross-site communication
% does not create new trade-off, exacerbate existing
% Having multiple base data replicas creates additional consideration for m



% \subsection{Component placement}
% There are two types of computational query processing operator can be
% involved in:
% \begin{itemize}
%   \item Update-triggered: For example, updating an index as a result to a corpus
%   update
%   \item Query-triggered: For example, index/cache lookup as a result to a query.
% \end{itemize}
% This can apply to any query processing operator, not only stateful ones.

% The placement determines how close (in terms of network round trip time) the
% operator is placed related to its sources of updates and queries.

% Deciding on placement schemes can lead to trade-offs cause by:
% - The benefits and costs of placing operators close to update sources versus close to query sources.
% - An operator might have multiple update and/or query sources.

% We can define ``levels'' of placement: on the same physical machine, on the same cluster, in the same DC.

% \section{Trade-offs}
% Summarize how the previously described design choices result to performance and
% efficiency trade-offs.

% Note: This may be redundant depending on how detailed those trade-offs are
% discussed in the previous section, but it is central to the thesis to make the
% argument that it is because of these trade-offs that we propose the QPU
% approach.

% An idea is to here focus on examples of applications that might choose different
% points in these trade-offs.

% \subsection{Implications of replicated data in derived state}
% Implication of query processing over AP storage systems:
% \begin{itemize}
%   \item If not carefully designed, concurrent non-conflicting updates may
%   result to conflicts on the derived state.
%   Example: write1: recordX:attributeA=1, write2: recordY:attributeA=1.
%   This results to: index\_update1: add recordX to (attributeA, 1),
%   index\_update2: add recordY to (attributeA, 1).
%   Therefore a ``set CRDT'' behavior is needed for indexes.
%   Generalize to state other than indexes.
%   \item Conflicting updates to the corpus data.
%   Ensure that conflict resolution on corpus data is reflected on derived data.
% \end{itemize}

% \subsection{CAP}
% Describe how query processing performance-availability is constraint by
% CAP in the case of replicated derived state.

% \subsection{Index and materialized view selection}
% \label{sec:index_view_selection}
% As discussed in chapter~\ref{ch:background} indexes are crucial to query processing performance in most database system.
% The use of indexes provides fast access to data,
% but also complicates updates operations since indexes need to be updated to reflect changes to the indexed data.
% Hence, there is a tradeoff involved in selecting which indices to materialize.
% Having too few or not having the appropriate indexes may force many queries to scan large parts of the dataset;
% Having too many indexes incurs high update costs.

% A similar tradeoff lies in the problem of selecting materialized views.
% Using an appropriate set of materialized views can significantly reduce query response time as processing a query by
% accessing a materialized view can be much faster than processing the query from the base data.
% On the other hand, materializing a view incurs an additional maintenance and storage space cost.

% Therefore, both the index and view selection problem involve a tradeoff between the reduced query response time
% from the one size,
% and write latency and memory/storage space overhead from the other.

% The index and view selection problems have been studied extensively.
% In particular, various commercial and research systems have focused on the problem of automated index selection
% \cite{valentin:db2advisor, chaudhuri:decadeselftuning}

% TODO: methods for finding a rewriting of a query using a set of materialized views -> orthogonal
