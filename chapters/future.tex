\section{Future Work}

\subsection{Placement policies}

In this work, we have focused on the mechanisms required for supporting flexible placement of state
and computations in geo-distributed query processing.
Chapter~\ref{ch:design_space} presents an analysis of the trade-offs involved in placement decisions,
and Chapter~\ref{ch:evaluation} presents an evaluation of the effects of placement decisions on query processing performance
and query result freshness.
However, our design relies on developers or system administrators for making placement decisions.
An important direction for future work is to study query processing state placement algorithms.
This can be expressed by the following problem statement:
Given a QPU graph (or more generally, a directed acyclic graph of stateful and stateless query processing operators),
a collection of processing nodes available for placing operators, organized in clusters, data centers and so on,
and a description of the placement of corpus data on processing nodes,
how can we compute an assignment of operators to processing nodes that optimally satisfies an optimization criterion.
This is a challenging problem because the inherent tensions between different optimization criteria mean that
optimizing for a given metrics incurs penalties to other metrics.
However, applications are rarely interested in a single metric.
Furthermore, placement decisions need to take into account the applications' workload characteristics.

\subsection{Dynamic query engine architectures}

Throughout this thesis, we make the assumption that QPU graphs are static.
Extending the current design with mechanisms and policies for online reconfiguration of QPU graphs,
with the aim of adapting to changes in the workload, is an interesting area for future investigation.
There are several directions to examine:

\begin{itemize}
  \item When a query processing unit that maintains an index or materialized view becomes too loaded,
  or the size of its state grows beyond a given threshold,
  the unit could decide to split its state into shards by spawning child QPUs,
  and offloading parts of its state to them.
  Conversely, when shards are underutilized, they could decide to be merged into a larger shard in order
  to reduce resource consumption.
  This requires extending query processing units with support for deploying other units,
  modifying their configuration during runtime, and modifying the QPU graph topology during runtime.

  \item Static placement strategies cannot respond to changing workloads.
  Adjusting the QPU graph's placement to workload changes requires the ability to migrate units.
  Employing existing state migration techniques in this work should not pose significant challenges.

  \item This thesis takes a simple approach in the area of the QPU architecture's query processing capabilities.
  A QPU graph is defined manually, in order to provide support for a pre-determined set of queries.
  Adding new queries, or materializing additional views or indexes requires manual reconfiguration of the graph,
  or deployment of a new graph.
  Interesting future work directions include techniques for automatically generating QPU graphs based on a
  given set of queries,
  adding new queries and materializing views and indexes on the fly.
  Existing works have proposed approaches for generating query processing operator graphs based on user-specified queries
  \cite{gjengset:noria, kate:pequod}.
  Extending this work with such techniques raises some of the problems described above, such as supporting online
  reconfiguration of the QPU graph.

\end{itemize}

\subsection{Consistent distributed queries}
\label{sec:future_consistent_snapshots}
In Proteus' implementation of the $Query()$ interface,
a query that requests the latest state snapshot is served from the most recent versions available at each stateful QPU
in the query's execution path, in a best-effort fashion.
When combined with asynchronous propagation of updates through the QPU graph,
this can result in cases in which a query observes different snapshots at different QPUs.
For example, consider that case of a QPU graph that maintains two materialized views.
An application performs a write operation that will eventually modify both views,
and subsequently issues a query that requires reading from both views.
The write operation is propagated to one of the views, but the message to the other view is delayed,
and, as a result, the query observes a snapshot that contains the write operation in one view,
and a snapshot that does not contain it in the other.
This can potentially lead to inconsistencies in query results.

This problem is similar to that of distributed transactions:
A query needs to be executed over a consistent snapshot across multiple indexes and materialized views (or index/view shards)
that are updated asynchronously.

Our design already provides a mechanism that could be built upon to provide consistent snapshots across QPUs:
stateful QPUs maintain versioned state,
and queries can specify a snapshot on which to be executed by providing a timestamp.
A possible solution could use an additional mechanism for determining the most recent snapshot that has been observed by
all QPUs that take part in the execution of a given query (stable snapshot).
This snapshot would be identified at the start of the execution of a query,
and then sub-queries in the query's execution would use the corresponding timestamp to request that snapshot.

An approach for identifying the most recent stable snapshot could be to periodically exchange
metadata between query processing units in the background;
Each unit would maintain a view of which updates other units have received and applied, based on these metadata.
This mechanism can benefit from the hierarchical nature of the QPU graph:
each QPU can summarize the view of its outgoing connections, and only propagate that summary to its parents.


\section{Discussion}

\subsection{Scope}

The query engine architecture presented in this thesis is not designed as a general-purpose query engine.
Instead, our design assumption is that each QPU architecture is designed for a specific application,
with a specific set of queries in mind.

Proteus, the framework that implements the query processing unit architecture pattern is well-suited for applications that:
\begin{itemize}
  \item Are query-heavy. Our design centers around the use of derived state (indexes, materialized views) for speeding up
  query processing.

  \item Have geo-distributed state, or geo-distributed query sources.
  This work focuses on the area geo-distributed query processing.
  A large body of research has focused on improving query processing performance in systems that do not involve
  wide area latencies.

  \item Use storage systems that lack query processing capabilities, or do not support derived state.
  Proteus' support for integration with existing storage systems,
  allows applications to use it as a query processing or derived state middleware.
\end{itemize}

Furthermore, the query engine architecture presented in this thesis can be applied in the design of database query processing
systems that aim to support flexible placement of derived state.

\subsection{Fault Tolerance}

Proteus' approach to fault-tolerance is based on redundancy.
When a QPU along the execution path of a query is not available, or fails during the execution of a query,
sub-queries to that QPU are retried, and, after a timeout, a failure response is returned to the client.
If a QPU can send a sub-query to multiple downstream connections, initially one is chosen,
and if that sub-query fails, then the QPU retries by sending the sub-query to a different downstream connection.
This mechanism can be used to construct query engines with redundant query execution paths.
For example, in the case of a materialized view, a secondary execution path that computed queries without accessing
the view can be used as a secondary path in case the materialized view fails.

\subsection{Data storage tier APIs}

The query engine design presented in this thesis is based on the assumption that the data storage tier exposes
two interfaces (Section~\ref{sec:storage_tier_api}):
An interface for iterating over the corpus data (list), and one for subscribing to notifications for changes to the
corpus data (subscribe).
The list interface is used for evaluating queries over the corpus by executing query processing operators over data streams
created by iterating over the corpus;
the subscribe interface is used for keeping derived state up-to-date with changes to the corpus.

While it is realistic to assume that most storage systems provide a list interface,
or interfaces that can be composed to achieve an equivalent functionality,
that is not the case for the subscribe interface.
Indeed, we have extended AntidoteDB and CloudServer (\S\ref{sec:implementation}) with Proteus-specific
notification mechanisms,
as such mechanisms were not initially available in these systems.

Proteus could be used with storage systems supporting a subset of the required interfaces.
However, this would result in some of the capabilities presented in this thesis not being available.
More specifically, if used with a data storage system that does not support the subscribe interface,
derived state QPUs would not support incremental updates.
Instead, those QPUs would need to periodically rebuild their state by scanning the corpus, using the list interface.
The query processing unit design already supports periodic rebuilding of derived state.

% \subsection{Data storage tier APIs}
% An additional consideration stems from the CAP impossibility theorem \cite{brewer:cap}.
% In the face of network partitions between data centers,
% geo-replicated databases must choose between strongly consistent (CP) and highly-available (AP) designs.
% In a strongly-consistent design, corpus replicas are kept up-to-date at all times.
% This provides the abstraction of a single replica system which simplifies application logic, but exposes users to high
% write response time due to the need for inter- data center communication between replicas in the critical path of each write operation.
% In a highly-available design, each corpus replica serves write operations locally, and replicas synchronize in the background, out of the critical path of write operations.
% This ensures low write response time and availability under network partitions,
% but causes replicas to accept concurrent conflicting updates and to temporary diverge.
% Highly-available designs use mechanisms for ensuring that replicas eventually converge to the same state despite
% conflicting updates, such as conflict-free data types \cite{Shapiro2011CRDTs}.
% In some cases, these mechanisms modify the effect of an already processed operation when a concurrent conflicting operation
% is received later by the replica.

% As an example, we can consider the case of the add-wins set.
% The
% A replica of the set receives an operation the removes an element from the set, updates its state,
% and modifies a secondary index accordingly.
% Later, the replica receives an operation that adds the same element in the set, and determines that it was concurrent with the
% remove operation.
% Based on the conflict resolution rule (add-wins) the element must appear in the set.
% The replica's state must be updated, and the result must be reflected in the materialized view.
% Conversely, a remove-wins set in the same scenario needs to update the materialized view with the reverse result.
% Therefore, in AP designs, derived state maintenance algorithms need to take into account concurrent conflicting updates,
% and conflict resolution policies, in order to avoid divergence between corpus and derived state.
