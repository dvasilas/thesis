\begin{tcolorbox}
The goal of this chapter is to prepare the ground so that the reader has the mental framework needed to understand the
rest of this document.

This includes:
\begin{itemize}
  \item Implicitly establishing a terminology to be used throughout the document.
  \item Establishing a ''world view'' by describing the system and data model that we consider, and the assumptions that
  we make
  \item Establishing concepts that will guide our design decisions in the following chapters (see
  Section~\ref{sec:requirements}).
  \item Introducing technical background that will be needed for the following chapters.
\end{itemize}
\end{tcolorbox}

\section{Models}
We consider a data serving system with a two-tiered architecture: a data storage tier and a query processing tier.

\begin{itemize}
\item A data storage tier, responsible providing access to data.
We use the terms \textit{storage system} or \textit{data store} for the system used for this tier, and \textit{base data}
or \textit{corpus} for its data.
\item The query processing tier,Â which is responsible for providing querying functionalities.
We use the terms \textit{query engine} or \textit{query (processing) system} for the system that implements this tier.
\end{itemize}

Disaggregating query processing from persistent storage is an approach used by various systems and storage
services such as Amazon Athena \cite{aws:athena}, Aurora \cite{aws:aurora}, and Google BigQuery
\cite{google:bigquery}.
In such systems, query processing is performed by a query engine independent from the storage system.

This model provides several benefits, such as:
\begin{itemize}
  \item Enabling independent storage and query processing scaling of resources (elasticity).
  \item Allowing on-demand, short-lived queries on already existing data without the need to migrate data.
  \item Enabling cloud providers to implement fine-grained pricing for querying services.
\end{itemize}

In this work, we consider the data storage tier as ``imposed'' and focus on the design of the query processing tier:
We use the data storage tier's functionalities, guarantees, as well as data distribution schemes as input parameters
in our design process.

In addition, one of our aims is that the query processing tier is agnostic of the data storage tier, and a query
system can interoperate with multiple different data storage tier implementations.
To achieve that, we specify the interconnection between the two tiers as a set of well-defined APIs, which we describe
in detail in the following section.

\subsection{Data storage tier}
The data storage tier is responsible for providing access to base data.
As described above, the tier can be implemented by different types of systems as long as it exposes the APIs expected by
the query processing tier, described later in this section.
Examples of systems implementing the data storage tier can be databases, file systems, cloud object storage systems,
or even streaming systems.

However, as in this work we study the design decisions related to the placement of the query engine's state and
computations relative to the base data, we consider a more specific data storage tier model, so that we can reason about
its properties and data distribution scheme.
More specifically, we consider a data storage tier implemented by a federation of geo-replicated storage systems
In the following Section we present in detail our data storage tier model.

\subsubsection{System model}
The data storage tier is implemented by a storage system (a database, file or cloud storage system) or a federation of
multiple, potentially heterogeneous storage system.
Each system is responsible for storing a dataset $D$.
In a federated system, the dataset of each storage system is independent, but the application logic may implement
replication across different systems (for example an application that replicates data across multiple cloud providers).
In addition, storage systems implement replication: each maintains one or more full replicas of its dataset, and may also
maintain partial replicas.
Finally, replicas are sharded: each replica partitions its data in non-overlapping parts, and a shard is responsible
for a part of the data.

We model the system infrastructure as a collection of \textit{sites}.
A site is as a group of nodes (servers, user devices) located in close geographic proximity.
It can represent a data center, a small group of servers serving as an edge Point of Presence \cite{google:infra}, of
a group of user devices in close proximity (in the same room or building).
A site is characterized by the following characteristics:
\begin{itemize}
  \item Network communication latency between nodes in different sites is significantly higher (typically an order of
  magnitude higher) \cite{pbailis:hats} compared to communication latency within a site.
  \item Network resources across sites are more limited and costly across sites.
  This is reflected in the pricing for cross-region data transfer in public cloud platforms.
  Using the AWS Pricing Calculator \cite{aws:costcalc} we see that data transfer to different AWS data centers
  (regions) costs double the price of intra-DC data transfer (0.02 and 0.01 USD per GB respectively).
\end{itemize}

% Sites can correspond to data centers or edge sites.
% We consider a system composed of data centers and edge sites.
% We assume that each edge site communicates with a single data center, that which is geographically
% closest to it.
% For the rest of the paper we consider, for the sake simplicity, a single data center and edge site.

% The storage tier runs in the data center, while the caching tier runs partially on servers located in the data center
% and partially on servers located on the edge site.
% Clients are located close the edge site, and perform read queries, while writes are performed directly at the data
% center.

\subsubsection{Data model}
% - In short, the corpus is a collection of records grouped in tables. Each record is identified by a unique key (can be a % composite key).
% - Each record also has associated attributes. An attribute is a key-value pair. Schema can be pre-defined or not.
% - Argue that this data model can express a variety of data models (relational, wide-column, object storage). \\
The data storage tier is responsible for storing a dataset, which is a collection of \textit{data items}.
We use the term \textit{data items} to refer to the unit of storage such as files, objects or database records.
Data items are organized in \textit{tables}, which can be organized in a hierarchical structure
(e.g. file system repositories), a flat namespace (e.g. object storage buckets), or a relational schema.

A data item is composed of a primary key, is associated with a set of attributes, and optionally a value.
The primary key can be used to \textit{efficiently} identify the data item, without requiring a scan.
We model attributes key-value pairs, therefore each data item is associated with a map of attribute keys and values
$\{AttrKey: AttrVal\}$.
We do not assume a strict schema for attributes: the attributes of each data item are independent of the attributes of
others.
We consider the data item's value as a blob of binary data.

We assume that all objects have at least one attribute, a ''timestamp``.
Timestamps can be of any datatype that provides a comparison operator which can be used to establish an at least partial
order between timestamps, such as Unix time or vector timestamps.

\subsubsection{API exposed to the query processing tier}

The data storage tier exposes to the query processing tier at least one of the following APIs:
\begin{itemize}
  \item An API for iterating over the corpus data (List)
  \item An API for subscribing to notification for changes to the corpus data.
% TODO: cite https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html
  \item An API for querying the corpus data.
\end{itemize}

\noindent
\textbf{API 1: List}

\noindent
This API provides a mechanism for retrieving the primary key and attributes of all objects in a given table:

$List(Table, [Timestamp_{low}, Timestamp_{high}))$ $\rightarrow$ $[ListResponse]$

\noindent
$ListResponse$ then contains all data items in $Table$ with $Timestamp_{low} \leq Timestamp < Timestamp_{high}$
in the form $(ID, {AttrKey: AttrVal})$.
$ListResponse$ may be implemented in different says, such a single response containing a set of
data items, or a stream in which each data item is sent as a record, or a handler with a $Next()$ method that returns a
data item each time it is called.
We don't assume any ordering in $ListResponse$.

$List$ can be implemented as an explicit API method This can provided as a list and a read operation.

\noindent
\textbf{API 2: List}
  for example triggers in traditional
  database management systems, or event notification mechanisms in cloud storage services.




% From the point of view of the query tier, the data storage tier can be models as a system that exposes (one or more of)
% the following APIs:





%  ---
% Each data item is associated with a primary key, $id$, that can be used to efficiently retrieve it, without requiring a scan.
% Data items are associated with a set of attributes, and optionally a value.

% We represent this as a tuple $(V, \{Attr: AttrVal\})$, where $V$ is the data item's value, and $\{Attr: AttrVal\}$ is a map from attributes keys to attribute values.
% Attributes can include system metadata (e.g. size), user-defined tags, or attributes computed from $V$.
% We use the notation $Attr(d)$ to refer to the attribute value of the attribute $Attr$ of data item $d$.

% However, $Attr(d)$ is a partial mapping: some data items may not have a value ($Null$) for $Attr$.

% We assume that every data item has at least one attribute, a ``last-modified'' timestamp, which we describe later in this Section.
% \end{itemize}
% This abstraction is compatible with several different data models, including object storage, document databases, key-value stores, wide-column stores, and relational databases.




% The data storage tier is deployed on
% It fully or partially replicates $D_i$ across different geo-locations, which we refer to as data centers.

% Each data center is partitioned multiple parts, and each partition is responsible for a non-overlapping subset of $D_i$.
% We assume that each database engine instance employs the same partitioning across all data centers, but different instances may employ different partitioning schemes.

% We assume that database engines support three operations: i) a read operation that, given a primary key, returns the value and attributes of the corresponding object, ii) a write operation that updates the value and attributes of a given data item (inserting a new data item can be represented as a write operation), and iii) a delete operation which removes a given data item from $D$.
% The unit of operation on the database engine is the transaction.

% A transaction may contain multiple operations, and is terminated by an abort (writes and deletes have no effect) or a commit (writes and deletes modify the corpus).
% When a transaction commits an update, the database system does not overwrite the data item with the result of the update, but creates a new version instead.
% Each data item version is associated with a version timestamp $vt$, which is one of the data item's attributes.

% We define as \textit{snapshot} a cut of the database's state, a state of data item state containing a version of every data item in the database.
% Each snapshot is identified by a timestamp $ts$.
% The snapshot $ts$ contains the version $vts$ of each data item $d$ in $D$ for which $vts \leq ts$ $\land$ $\nexists$ $vts'$: $vts \leq vts' < ts$.

% We also assume that database engines provide the following mechanisms:


% \textbf{Data (corpus) model} \\
% In short, the corpus is a collection of records grouped in tables. Each record is identified by a unique key (can be a
% composite key).
% Each record also has associated attributes. An attribute is a key-value pair. Schema can be pre-defined or not.

% Argue that this data model can express a variety of data models (relational, wide-column, object storage). \\

% \subsection{Corpus data and system model}
% The corpus is a data set $D$, which is a collection of \textit{data items} with the following properties:
% \begin{itemize}
% \item A data item $d$ in $D$ is associated with a primary key, $id$, that can be used to efficiently retrieve $d$.
% \item A data item $d$ is composed of a value and a collection of attributes.
% We represent this as a tuple $(V, \{Attr: AttrVal\})$, where $V$ is the data item's value, and $\{Attr: AttrVal\}$ is a map from attributes keys to attribute values.
% Attributes can include system metadata (e.g. size), user-defined tags, or attributes computed from $V$.
% We use the notation $Attr(d)$ to refer to the attribute value of the attribute $Attr$ of data item $d$.
% However, $Attr(d)$ is a partial mapping: some data items may not have a value ($Null$) for $Attr$.
% We assume that every data item has at least one attribute, a ``last-modified'' timestamp, which we describe later in this Section.
% \end{itemize}
% This abstraction is compatible with several different data models, including object storage, document databases, key-value stores, wide-column stores, and relational databases.


% Logically, we consider this tier as a component that may expose some of the following APIs:
% \begin{itemize}
%   \item An API for iterating over the corpus data.
%   \item An API for subscribing to notification for changes to the corpus data.
%   \item An API for querying the corpus data.
% \end{itemize}
% This component can be implementing by an actual storage system that stores the corpus data (in that case it might
% provide all three APIs), or by an event stream providing only the subscription API.

% Also:
% \begin{itemize}
%   \item Describe our assumptions on the consistency guarantees of the storage tier.
%   \item State that we consider this tier ''imposed''; we build on top of it.
% \end{itemize}

\subsection{Query processing tier}
The query processing tier is responsible for providing the functionality of attribute-based data retrieval.
In more detail, given a query expressed as a predicate on attributes and a table, the query processing tier is
responsible for providing the primary keys and attributes of all data items in the given table that match the given
predicate.

As query language, we consider a subset of SQL that contains only expressions of the form: \\

\noindent
$SELECT$ $projection$ $FROM$ $Table$ $WHERE$ $predicate$
\noindent
where
\begin{itemize}
  \item $projection$ is the list of attributes to be included in the query response.
  It has the form $AttrKey_1$, $AttrKey_2$, ..., $AttrKey_N$
  \item $predicate$: has the form: \\ $rangePredicate_1$ $AND$ $rangePredicate_2$ AND ... AND $rangePredicate_N$, \\
  where $rangePredicate_i$ an expression of the form $attrVal_{low}$ $\leq$ $attrKey$ $<$ $attrVal_{high}$.
\end{itemize}

Given a query $Q$ represented as ($projection$, $table$, $predicate$)
and a data item $d$ represented as ($table$, $id$, $attributes$), $d$ satisfies $Q$ if:
\begin{itemize}
  \item $Q.table$ = $d.table$: the data item belongs in the table referred by the query.
  \item $\forall$ ($attrVal_{low}$ $\leq$ $attrKey$ $<$ $attrVal_{high}$) $\in$ $Q.predicate$:
  $attrKey$ $\in$ $d.attributes$ and :  $attrVal_{low}$ $\leq$ $attrVal$ $<$ $attrVal_{high}$:
  the data item contains all attributes included in the query's predicate.
  \item $\forall$ 
\end{itemize}


% The query subsystem provides the functionality of attribute-based queries.

% A query is defined as a set of tuples $Q = \{(Attr, [AttrVal_1, AttrVal_2))\}$ such that $AttrVal_1 \leq AttrVal_2$.

% We refer to each tuple in a query as a predicate.

% A data item $d$ satisfies $Q$ if $\forall$ $(Attr, [AttrVal_1, AttrVal_2))$ $\in$ $Q$: $Attr(d)$ $\neq$ $Null$ $\land$ $AttrVal_1 \leq Attr(d) < AttrVal_2$.

% Each query contains a predicate on the version timestamp attribute.
% Assuming a predicate $(vt, [t_1, t_2))$, we distinguish the following query semantics:
% \begin{itemize}
% \item \textbf{Snapshot queries.} If $t_1 = t_2 = t$, then the query is executed against the snapshot of $D$ with timestamp $vt \leq t$ $\land$ $\nexists$ $vt'$: $vt \leq vt' < t$.
% \item \textbf{Persistent queries.} if $t_2 >$ $vt_{latest}$, where $vt_{latest}$ is the version timestamp created by the last committed transaction, the query is executed against each new data item version $vt$ created by each transaction commit, while $vt < t_2$.
% \end{itemize}

% We define the set of all data items in $D$ that satisfy a query $Q$ as $Q_r$.
% However, the output $Q_o$ of a query may contain additional data items (false positives), or not contain some of the elements of $Q_r$ (false negatives).
% We define the distance between $Q_o$ and $Q_r$ as query result consistency.


% \begin{itemize}
%   \item Describe the intended functionality.
%   \item Sketch the query language.
% \end{itemize}

Query systems often maintain \textit{derived} state, such as indexes, materialized views or caches, which is
derived from the base data.
Derived state needs to be updated to reflect changes to the base data.
For indexes and materialized views this involves updating their entries according to the base data changes.
For caches this involves invalidating obsolete cache entries.


\subsubsection{Consistency between corpus data and query responses}

\section{Query processing system performance evaluation}
\label{sec:requirements}

The aspects of a query processing system's performance can be categorized in two groups:
\textit{efficiency} and \textit{effectiveness} \cite{buttcher:informationretrieval}.
Efficiency can be measured in terms of time (milliseconds per query) of utilized resources (bytes in memory per based
data record).
Evaluating efficiency involves metrics such as response time, throughput, scalability.
Effectiveness is a measure of how well a query processing system achieves its intended purpose.
Evaluating effectiveness involves measures such as precision and recall.

\subsection{Evaluating Efficiency}

The most visible aspect of efficiency is the \textit{response time} experienced by a user between issuing a query and
receiving the corresponding response.
Since the query system needs to support many simultaneous users, the \textit{query throughput}, measured in queries per
second becomes an important performance factor.
In addition, since response time is the metric that affects user experiences, a performance factor is how
\textit{response time} scales with \textit{query throughput}.
Together, \textit{query throughput} and the relation between \textit{response time} and \textit{query throughput}
characterize the system's \textit{scalability}.

\subsubsection{Response time}
Response time - the amount of between making a request and receiving the corresponding response -
is among important metrics for the quality of user-facing service.

A number of studies and experiments have been studied the effects of response time to user experience.
Results show that response time is among factors that have the largest effect users' subjective perception of the
quality of a system.
Users have been shown to perceive websites that load faster as more interesting \cite{ramsay/retrievaltimesinvestigation}.
On the other hand, long response times increase user frustration \cite{ceaparu:userfrustration} and even compromises
user's conceptions of the security of the system \cite{bouch:qualityeyebeholder}, making users for example less likely to
make purchases on websites with long loading times.

As a result, even small increases in user-perceived response times can result in drops in web traffic and
therefore sales, as industry reports have indicated.
Experiments by the Google and Bing search engines have shown that loner page loading times have a significant impact on
metrics such as time to click, repeat site usage, and queries per visit \cite{schurman:rerformanceuserimpact}.
A study from Akamai on the impact of travel site performance on consumers showed that more than half of the users will
wait three seconds or less before abandon the site \cite{akamai:travelsiteperformance}.
Finally, a comparison shopping service (Shopzilla) has reported that a website re-engineering project that achieved a
speedup in page load time from 6-9 seconds down to 1.2 seconds resulted in 25\% increase in page views and 5-12\%
increase in revenue \cite{dixon:shopzillasiteredo}

\subsection{Evaluating Effectiveness}

Effectiveness is a measure of how well a query processing system achieves its intended purpose.
In the field of information retrieval, the key notion linked effectiveness is \textit{relevance}
\cite{buttcher:informationretrieval}:
Given a user's information need represented by a search query, each document in a given a document collection, is either
relevant or non-relevant with respect to the information need.
The two most used measures in information retrieval systems evaluation are precision and recall.
Recall is the fraction of relevant documents contained in the query result.
It is affected by false-negatives: not including relevant documents in the query result.
Precision is the fraction of relevant documents among the documents contained in the query result.
It is affected by false-positives: including non-relevant documents in the query result.

The difference information retrieval and the query processing model in this work is that here there is no notion of a
ranking function.
In information retrieval relevance is a spectrum: documents can be more or less relevant to a given query.
Here, relevance is binary: a record is either relevant (satisfies the given query) or it is not.


A factor that can affect query effectiveness even when relevance is binary is the consistency between base
and derived data.
In traditional database systems, derived data are kept consistent with base data by being updated in the critical path
of each base data update.
As a result, queries are guaranteed to return all relevant and only relevant results.
However, in systems that implement asynchronous (lazy) derived data maintenance policies \cite{tan:diffindex,
qi:secondaryindexconsistencyanalysis, shukla:schemaagnostic}. derived data can be stale with respect to base data.
This can results in both false-positives and false-negatives.

We use the notion of \textit{freshness} to refer to the measure of inconsistency between base and derived data due to
asynchronous maintenance, which results in lower query processing effectiveness.

TODO: paper about freshness metrics.
% Freshness - Correctness - Consistency

TODO: Availability
TODO: Operational Cost


\subsection{End-user and system operator requirements}

Another categorization of query processing performance aspects can be made between end-user and system operator
requirements.
End-user requirements are performance factors such as response time, effectiveness and availability, which are directly
visible to end-users and affect their experience
System operator requirements such as scalability and cost, which are not directly visible to end-users but are important
for the system's operation.


In this section, present the factors that affect the experience and satisfaction of end-users of the query processing
tier.


% \textbf{Freshness}
% \begin{itemize}
%   \item Define freshness intuitively, as query results being up-to-date with the corpus data.
%   \item Present evidence of use cases in which getting fresh results is important.
% \end{itemize}

% \textbf{Correctness} \\
%   Define correctness using recall and precision.

\textbf{Availability} \\
  Present evidence of the negative effects of downtimes.

% \textbf{Consistency}

% \subsection{System provider requirements}
% In this section, we present factors that are indirectly affect end-users, but are important for the system operator.

\textbf{Scalability} \\
Present evidence of about the scale of internet services nowadays.

\textbf{Operational Cost} \\
The cost of operating the query processing system. Can split to fixed (monthly) cost, and per-query cost.

\bibliographystyle{unsrt}
\bibliography{refs}