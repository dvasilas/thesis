% \begin{tcolorbox}
% The goal of this chapter is to prepare the ground so that the reader has the mental framework needed to understand the
% rest of this document.

% This includes:
% \begin{itemize}
%   \item Implicitly establishing a terminology to be used throughout the document.
%   \item Establishing a ''world view'' by describing the system and data model that we consider, and the assumptions that
%   we make
%   \item Establishing concepts that will guide our design decisions in the following chapters (see
%   Section~\ref{sec:requirements}).
%   \item Introducing technical background that will be needed for the following chapters.
% \end{itemize}
% \end{tcolorbox}

\section{Models}
We consider a data serving system with a two-tiered architecture: a data storage tier and a query processing tier.

\begin{itemize}
\item The data storage tier is responsible for providing access to data.
We use the terms \textit{storage system} or \textit{data store} for the system that implement this tier, and the terms
\textit{base data} or \textit{corpus} for its data.
\item The query processing tier is responsible for providing the functionality to identify and retrieve data using
queries on secondary attributes (Section~\ref{subsec:query_prcessing_tier}).

We use the terms \textit{query engine} or \textit{query (processing) system} for the system that implements this tier.
\end{itemize}

Disaggregating query processing from the storage engine is an approach used by various systems and cloud
services such as Amazon Athena \cite{aws:athena}, Aurora \cite{aws:aurora}, and Google BigQuery
\cite{google:bigquery}.
In these systems, query processing is performed by a query engine independent from the storage system.

This model provides several benefits:
\begin{itemize}
  \item Storage and query processing resources can scale independently (elasticity).
  \item It enables on-demand, short-lived queries on already existing data without the need to migrate data.
  \item It enabling cloud providers to implement fine-grained pricing for querying services.
\end{itemize}

In this work, we focus on the design of the query processing tier and consider the data storage tier as ``imposed'':
we consider the data storage tier's functionalities, guarantees, and data distribution schemes as input parameters in
our design.

One of our design goals
(TODO: link to design goals in the next chapter)
is that the query processing tier should be agnostic of the data storage tier.
A query system should be able to interoperate with multiple different data storage tier implementations.
To achieve that, we model the interconnection between tiers as a set of well-defined APIs, which we describe
in detail in the following section.


\subsection{Data storage tier}

TODO: [...] or even streaming systems.

The data storage tier is a broad abstraction that can include any system that can be used to store and retrieve data.
This can include databases, file systems, cloud object storage systems.

As described above, in this work we view this tier as an external, underlying system that our design can build upon.
However, any efficient query processing tier design needs to take into account the properties and characteristics of the
data storage tier, most importantly its data distribution scheme.
To address that, we adopt a less broad data storage tier definition.
More specifically, we model a data storage tier as a federation of geo-replicated storage systems.
In the following Section, we present in detail our data storage tier model.


\subsubsection{System model}
The data storage tier is implemented by a storage system (a database, file system or cloud storage system) or a
federation of multiple, potentially heterogeneous storage systems.
Each system is responsible for storing a dataset $D$.
In a federated system, the dataset of each storage system is independent, but the application logic may implement
replication across different systems (for example an application that replicates data across multiple cloud providers).
In addition, storage systems implement replication:
each storage system maintains one or more full replicas of its dataset, and may also maintain partial replicas.
Finally, replicas are sharded: each replica partitions its data in non-overlapping parts, and a shard is responsible
for a part of the data.

We model the infrastructure on which the data storage tier runs as a collection of \textit{sites}.
A site is a group of nodes (servers, user devices) with the following characteristics:
\begin{itemize}
  \item Network communication latency between nodes in different sites is significantly higher (typically an order of
  magnitude higher) \cite{pbailis:hats} compared to communication latency within a site.
  \item Network resources across sites are more limited and costly across sites.
  This is reflected in the pricing for cross-region data transfer in public cloud platforms.
  Using the AWS Pricing Calculator \cite{aws:costcalc} we see that data transfer to different AWS data centers
  (regions) costs double the price of intra-DC data transfer (0.02 and 0.01 USD per GB respectively).
\end{itemize}

A site can correspond to a data center, a group of servers serving as an edge Point of Presence \cite{google:infra}, or
a group of user devices in close proximity (in the same room or building).


\subsubsection{Data model}
The corpus dataset is a collection of \textit{data items}, organized in \textit{tables}.
We use the term \textit{data item} to refer to the unit of stored data:
Depending on the storage system, a data item may correspond to a file, and object, or a database record.
Tables may be organized in a hierarchical structure (file system repositories), a flat namespace (object store buckets),
or a relational schema.

A data item is composed of a primary key, a set of attributes, and optionally a value.
The primary key can be used to efficiently identify and retrieve the data item, without requiring a scan.
Attributes are key-value pairs: each data item is associated with a map of attribute keys and values
$\{AttrKey: AttrVal\}$.
We do not assume a strict schema for attributes: the attributes of each data item are independent of the attributes of
others.
Finally, we consider the data item's value as a blob of binary data.

This data model can express the data model of multiple different types of storage systems:
\begin{itemize}
  \item Object stores, such as AWS S3: \\
  The data storage tier can be implemented by an object store.
  In that case, data items correspond to objects and tables to buckets.
  In addition, a data item's value corresponds to the object's content, and attributes correspond to object
  tags \cite{awss3:tagging}.
  \item Wide-column stores, such as Amazon DynamoDB, Google's Bigtable or Apache Cassandra: \\
  In a data storage tier implemented by a wide-column store:
  \begin{itemize}
    \item In both data models data is organized in tables.
    \item Data items correspond to table rows and attributes correspond to columns.
    \item Data items' values are empty.
  \end{itemize}
  \item Relational databases: \\
  Similarly to the wide-column data model, the relational model can be expressed by representing table records as data items,
  and columns as attributes.
  The difference between the two models is that while in the relational model each table has a schema that defines the
  names and format of its columns, in the wide-column model column names and format can vary from row to row in the same
  table.
  \item Document stores, such as MongoDB: \\
  The described data model is partially compatible with the document store data model.
  In the case of a data storage tier implemented by a document store, tables correspond to document collections, and
  data items correspond to documents.
  A document's identifier can be represented as a data item's primary key, while document attributes can be represented
  as attributes.
  However, the described data model does not model complex attribute types such as lists and maps which are supported by
  document stores.
  \item File systems: \\
  In a data storage tier implemented by a file system, data items correspond to files and tables correspond to file
  system repositories.
  A data item's primary key corresponds to the corresponding file's name, the value to the file's content, and attributes
  correspond to extended file attributes.
\end{itemize}

This general data model, which is able to express different existing data models, caters to the design goal mentioned
above:
Allowing the query processing tier to be agnostic of the underlying data storage tier, and be compatible with different
storage tier implementations. \\

\noindent \textbf{Timestamps} \\
We assume that objects are ''versioned``.
Each object is associated with a timestamp, which is one of it's attributes.
A timestamp can be implemented by any data type that provides a comparison operator which can be used to establish an
at least partial order between timestamps, such as Unix time or vector timestamps.


\subsubsection{Data storage tier API}

The data storage tier exposes at least one of the following APIs:
\begin{itemize}
  \item An API for iterating over the corpus data (List).
  \item An API for subscribing to notification for changes to the corpus data (Subscribe).
  \item An API for querying the corpus data (Select).
\end{itemize}

\noindent
\textbf{API 1: List}

\noindent
This API provides a mechanism for retrieving the primary key and attributes of all objects in a given table:

$List(Table, [Timestamp_{low}, Timestamp_{high}))$ $\rightarrow$ $[ListResponse]$

\noindent
Given a table name ($Table$) and a range of timestamps ($[Timestamp_{low}, Timestamp_{high})$),
$ListResponse$ contains all data items in $Table$ with $Timestamp_{low} \leq Timestamp < Timestamp_{high}$.
Each data item in $ListResponse$ is represented as a tuple $(ID, \{AttrKey: AttrVal\})$, containing the data item's
primary key ($ID$), and attributes ($\{AttrKey: AttrVal\}$).

$ListResponse$ may be implemented in different ways, such a single response containing a set of
data items, or a stream in which each data item is sent as a record, or an iterator in which calling a $Next()$ method
returns the following data item.
Finally, We don't assume any ordering in $ListResponse$.

The $List$ API may be provided as an explicit API method or implemented as a combination of a \textit{list} and a
\textit{read} (get) operation.

Depending on its versioning mechanism, the storage system implementing the data storage tier may not support the
listing API for any range of timestamps.
For example, in a storage system that does not provide multi-versioned storage, $List$ will return the latest version of
each data item.
For simplicity, we assume the $List$ API as specified above.
In Section
TODO
we describe how our design can cater for a $List$ API without support for Timestamp ranges.
\\

\noindent
\textbf{API 2: Subscribe}

\noindent
This API provides a mechanism for subscribing to notification for updates to data items in a given table:

$Subscribe(Table, [Timestamp_{low}, Timestamp_{high}))$ $\rightarrow$ $[SubscribeResponse]$

\noindent
Given a table name ($Table$) and a range of timestamps ($[Timestamp_{low}, Timestamp_{high})$),
$Subscribe$ initiates a stream called $SubscribeResponse$.
For each update performed in a data item $d$ in $Table$, creating a new version of $d$ with
$Timestamp_{low} \leq Timestamp < Timestamp_{high}$, a record is sent in $SubscribeResponse$.
$ListResponse$ records have the form $(ID, \{AttrKey: (AttrVal_{old}, AttrVal_{new})\})$:
each record contains the update data item's attributes before and after the update.
If an operation updates more than one data items, then a $ListResponse$ record is sent for each updated
data item.
If an attribute is created by the update, then its old value has the special value $null$.
Conversely, if an attribute is deleted by the update, then its new value has the $null$ value.

Various systems provide mechanisms that can be used to implement the $Subscribe$ API.
Examples include triggers in traditional database management systems \cite{mariadb:triggers}, and event notification
mechanisms in cloud storage services \cite{awss3:notifications}.
\\

\noindent
\textbf{API 3: Select}

\noindent
This API provides a mechanism for identifying data items based on their attributes:

$Select(Table, Predicate, [Timestamp_{low}, Timestamp_{high}))$ $\rightarrow$ $[SelectResponse]$,
where $Predicate$ is a map containing attribute keys and ranges:
$\{AttrKey: [AttrVal_{low}, AttrVal_{high})\}$.

Given a table name ($Table$), a range of timestamps ($[Timestamp_{low}, Timestamp_{high})$), and
a predicate consisting of attributes keys and ranges of values
($\{AttrKey: [AttrVal_{low}, AttrVal_{high})\}$), $Select$ returns $SelectResponse$.
$SelectResponse$ contains all data items in $Table$ that have all attributes contained in $Predicate$ and
their values are within the ranges specified in $Predicate$.

$Select$ can be expressed as an SQL query with the form: \\
\noindent
$SELECT$ $AttrKey_1$, $AttrKey_2$, ..., \\
$FROM$ $Table$ \\
$WHERE$ \\
$AttrKey_1$ $IS$ $NOT$ $NULL$ $AND$ $AttrVal_{low}$ $\leq$ $AttrKey_1$ $<$ $AttrVal_{high}$
$AND$ $AttrKey_2$ $IS$ $NOT$ $NULL$ $AND$ $AttrVal_{low}$ $\leq$ $AttrKey_2$ $<$ $AttrVal_{high}$
$AND$ ... \\
$AND$ $Timestamp_{low}$ $\leq$ $Timestamp$ $<$ $Timestamp_{high}$

$Select$ may be provided as a subset of a more expressive query language, such as in relational database
systems that support a full SQL query language. \\

\noindent
As we further discuss in Chapter
TODO,
the two tiers interoperate through these well-defined APIs.
This allows the query processing tier to be agnostic of the data storage tier, and compatible with any storage system
that exposes the described APIs.
As an example, the query processing tier can work on top of a streaming system that does not persist data but exposes
the $Subscribe$ API.

For the rest of this document, we assume for simplicity that the data storage tier exposes the $List$ and $Subscribe$
API as described here.
In Section
TODO,
we discuss the implications of the data storage tier exposing only one of the APIs to the query processing tier
functionality.
In addition we discuss the implications of $List$ and $Subscribe$ not supporting a range of timestamps but rather
returning results about the most recent timestamp, and how the query processing tier can make use of the $Select$ API.

\subsection{Query processing tier}
\label{subsec:query_prcessing_tier}
The query processing tier is responsible for providing the functionality of attribute-based data retrieval.
In more detail, given a query expressed as a predicate on attributes and a table, the query processing tier is
responsible for providing the primary keys and attributes of all data items in the given table that match the given
predicate.

As query language, we consider a subset of SQL that contains only expressions of the form: \\

\noindent
$SELECT$ $projection$ $FROM$ $Table$ $WHERE$ $predicate$
\noindent
where
\begin{itemize}
  \item $projection$ is the list of attributes to be included in the query response.
  It has the form $AttrKey_1$, $AttrKey_2$, ..., $AttrKey_N$
  \item $predicate$: has the form: \\ $rangePredicate_1$ $AND$ $rangePredicate_2$ AND ... AND $rangePredicate_N$, \\
  where $rangePredicate_i$ an expression of the form $attrVal_{low}$ $\leq$ $attrKey$ $<$ $attrVal_{high}$.
\end{itemize}

Given a query $Q$ represented as ($projection$, $table$, $predicate$)
and a data item $d$ represented as ($table$, $id$, $attributes$), $d$ satisfies $Q$ if:
\begin{itemize}
  \item $Q.table$ = $d.table$: the data item belongs in the table referred by the query.
  \item $\forall$ ($attrVal_{low}$ $\leq$ $attrKey$ $<$ $attrVal_{high}$) $\in$ $Q.predicate$:
  $attrKey$ $\in$ $d.attributes$ and :  $attrVal_{low}$ $\leq$ $attrVal$ $<$ $attrVal_{high}$:
  the data item contains all attributes included in the query's predicate.
  \item $\forall$
\end{itemize}


% The query subsystem provides the functionality of attribute-based queries.

% A query is defined as a set of tuples $Q = \{(Attr, [AttrVal_1, AttrVal_2))\}$ such that $AttrVal_1 \leq AttrVal_2$.

% We refer to each tuple in a query as a predicate.

% A data item $d$ satisfies $Q$ if $\forall$ $(Attr, [AttrVal_1, AttrVal_2))$ $\in$ $Q$: $Attr(d)$ $\neq$ $Null$ $\land$ $AttrVal_1 \leq Attr(d) < AttrVal_2$.

% Each query contains a predicate on the version timestamp attribute.
% Assuming a predicate $(vt, [t_1, t_2))$, we distinguish the following query semantics:
% \begin{itemize}
% \item \textbf{Snapshot queries.} If $t_1 = t_2 = t$, then the query is executed against the snapshot of $D$ with timestamp $vt \leq t$ $\land$ $\nexists$ $vt'$: $vt \leq vt' < t$.
% \item \textbf{Persistent queries.} if $t_2 >$ $vt_{latest}$, where $vt_{latest}$ is the version timestamp created by the last committed transaction, the query is executed against each new data item version $vt$ created by each transaction commit, while $vt < t_2$.
% \end{itemize}

% We define the set of all data items in $D$ that satisfy a query $Q$ as $Q_r$.
% However, the output $Q_o$ of a query may contain additional data items (false positives), or not contain some of the elements of $Q_r$ (false negatives).
% We define the distance between $Q_o$ and $Q_r$ as query result consistency.


% \begin{itemize}
%   \item Describe the intended functionality.
%   \item Sketch the query language.
% \end{itemize}

Query systems often maintain \textit{derived} state, such as indexes, materialized views or caches, which is
derived from the base data.
Derived state needs to be updated to reflect changes to the base data.
For indexes and materialized views this involves updating their entries according to the base data changes.
For caches this involves invalidating obsolete cache entries.


\subsubsection{Consistency between corpus data and query responses}

\section{Query processing system performance evaluation}
\label{sec:requirements}

The aspects of a query processing system's performance can be categorized in two groups:
\textit{efficiency} and \textit{effectiveness} \cite{buttcher:informationretrieval}.
Efficiency can be measured in terms of time (milliseconds per query) of utilized resources (bytes in memory per based
data record).
Evaluating efficiency involves metrics such as response time, throughput, scalability.
Effectiveness is a measure of how well a query processing system achieves its intended purpose.
Evaluating effectiveness involves measures such as precision and recall.

\subsection{Evaluating Efficiency}

The most visible aspect of efficiency is the \textit{response time} experienced by a user between issuing a query and
receiving the corresponding response.
Since the query system needs to support many simultaneous users, the \textit{query throughput}, measured in queries per
second becomes an important performance factor.
In addition, since response time is the metric that affects user experiences, a performance factor is how
\textit{response time} scales with \textit{query throughput}.
Together, \textit{query throughput} and the relation between \textit{response time} and \textit{query throughput}
characterize the system's \textit{scalability}.

\subsubsection{Response time}
Response time - the amount of between making a request and receiving the corresponding response -
is among important metrics for the quality of user-facing service.

A number of studies and experiments have been studied the effects of response time to user experience.
Results show that response time is among factors that have the largest effect users' subjective perception of the
quality of a system.
Users have been shown to perceive websites that load faster as more interesting \cite{ramsay/retrievaltimesinvestigation}.
On the other hand, long response times increase user frustration \cite{ceaparu:userfrustration} and even compromises
user's conceptions of the security of the system \cite{bouch:qualityeyebeholder}, making users for example less likely to
make purchases on websites with long loading times.

As a result, even small increases in user-perceived response times can result in drops in web traffic and
therefore sales, as industry reports have indicated.
Experiments by the Google and Bing search engines have shown that loner page loading times have a significant impact on
metrics such as time to click, repeat site usage, and queries per visit \cite{schurman:rerformanceuserimpact}.
A study from Akamai on the impact of travel site performance on consumers showed that more than half of the users will
wait three seconds or less before abandon the site \cite{akamai:travelsiteperformance}.
Finally, a comparison shopping service (Shopzilla) has reported that a website re-engineering project that achieved a
speedup in page load time from 6-9 seconds down to 1.2 seconds resulted in 25\% increase in page views and 5-12\%
increase in revenue \cite{dixon:shopzillasiteredo}

\subsection{Evaluating Effectiveness}

Effectiveness is a measure of how well a query processing system achieves its intended purpose.
In the field of information retrieval, the key notion linked effectiveness is \textit{relevance}
\cite{buttcher:informationretrieval}:
Given a user's information need represented by a search query, each document in a given a document collection, is either
relevant or non-relevant with respect to the information need.
The two most used measures in information retrieval systems evaluation are precision and recall.
Recall is the fraction of relevant documents contained in the query result.
It is affected by false-negatives: not including relevant documents in the query result.
Precision is the fraction of relevant documents among the documents contained in the query result.
It is affected by false-positives: including non-relevant documents in the query result.

The difference information retrieval and the query processing model in this work is that here there is no notion of a
ranking function.
In information retrieval relevance is a spectrum: documents can be more or less relevant to a given query.
Here, relevance is binary: a record is either relevant (satisfies the given query) or it is not.


A factor that can affect query effectiveness even when relevance is binary is the consistency between base
and derived data.
In traditional database systems, derived data are kept consistent with base data by being updated in the critical path
of each base data update.
As a result, queries are guaranteed to return all relevant and only relevant results.
However, in systems that implement asynchronous (lazy) derived data maintenance policies \cite{tan:diffindex,
qi:secondaryindexconsistencyanalysis, shukla:schemaagnostic}. derived data can be stale with respect to base data.
This can results in both false-positives and false-negatives.

We use the notion of \textit{freshness} to refer to the measure of inconsistency between base and derived data due to
asynchronous maintenance, which results in lower query processing effectiveness.

TODO: paper about freshness metrics.
% Freshness - Correctness - Consistency

TODO: Availability
TODO: Operational Cost


\subsection{End-user and system operator requirements}

Another categorization of query processing performance aspects can be made between end-user and system operator
requirements.
End-user requirements are performance factors such as response time, effectiveness and availability, which are directly
visible to end-users and affect their experience
System operator requirements such as scalability and cost, which are not directly visible to end-users but are important
for the system's operation.


In this section, present the factors that affect the experience and satisfaction of end-users of the query processing
tier.


% \textbf{Freshness}
% \begin{itemize}
%   \item Define freshness intuitively, as query results being up-to-date with the corpus data.
%   \item Present evidence of use cases in which getting fresh results is important.
% \end{itemize}

% \textbf{Correctness} \\
%   Define correctness using recall and precision.

\textbf{Availability} \\
  Present evidence of the negative effects of downtimes.

% \textbf{Consistency}

% \subsection{System provider requirements}
% In this section, we present factors that are indirectly affect end-users, but are important for the system operator.

\textbf{Scalability} \\
Present evidence of about the scale of internet services nowadays.

\textbf{Operational Cost} \\
The cost of operating the query processing system. Can split to fixed (monthly) cost, and per-query cost.

\bibliographystyle{unsrt}
\bibliography{refs}