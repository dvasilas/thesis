\section{Query Processing in Relational Database Systems}

\section{Query Processing in NoSQL Datastores}

\subsection{NoSQL Datastores}

\subsubsection{NoSQL Data models}

\subsubsection{Partitioning}
\label{sec:partitioning}

Partitioning is data distribution technique, in which a database's records are split into subsets called partitions so
that different partitions can be assigned to different nodes (also known as sharding).

The goal of partitioning is to spread data and load evenly across nodes.
When implemented efficiently, it enables horizontal scaling:
doubling the number of nodes in the system should make the system able to handle double the volume of data, and
should double the system's read and write throughput.

The sharding techniques commonly used in NoSQL systems are:

\bigskip
\noindent
\textbf{Range partitioning.}
Range partitioning assigns a continuous range of keys to each partition.
These ranges of key are not necessarily evenly spaced, because data may not be evenly distributed.
Partition boundaries might be chosen manually by an administrator, or the database can choose them automatically.

Within each partition keys are kept in sorted order.
This has the advantage that range queries on the partitioning key are efficient:
it is easy to determine which partitions contain keys of a given range, and within each partition the key can be treated
as an index.

The downside of this partitioning scheme is that certain access patterns can lead to hotspots.
Therefore, systems that implement range partitioning need mechanisms for detecting and resolving hotspots, by splitting
overburdened shards.

This partitioning strategy is used by Bigtable, its open source equivalent HBase \cite{hbasebigtable:comparison}.

\bigskip
\noindent
\textbf{Hash partitioning.}
An alternative approach that avoids the risks of skew and hotspots is to use a hash function to determine the partition
for a given key.
Hash partitioning assigns each partition a range of hashes --- rather than a range of keys --- and every key whose has
falls within a partition's range is handled by that partition.

This partitioning scheme is efficient at distributing keys fairly among partitions.
However, this approach does not allow for efficient range queries, as adjacent keys are scattered across multiple
partitions.

MongoDB introduced hash partitioning in version 2.4 \cite{mongo:hashpartitioning}.

\subsection{Query Processing}
\subsubsection{Secondary indexes}

A common technique used to support efficient filter queries the use of secondary indexes (secondary indexing).

A secondary index is an additional structure that is derived from the primary data, and stores data in a form that
provides a way to efficiently access records in a database by means other than the primary key.

Essentially, a secondary index is a key-value structure where the key is a \textit{term} (an attribute or key of the
database record other than the primary key) and the
value is a list of primary keys of all the records that contain that term (a \textit{posting list}).

The following data structures are commonly used for implementing secondary indexes:

\medskip
\noindent
\textbf{B-Trees}

\medskip
\noindent
\textbf{LSM-Trees}

\bigskip

\noindent
TODO:
In this work, ...

\bigskip
\noindent
Secondary indexing is an instance of a general system design pattern:
having the same data represented in different formats to address different access patterns.
Database tables are the primary copy of data.
Derived copies of the data transform or represent the primary copy differently in order to satisfy certain access patterns.
Adding a secondary index does not affect the contents of the database; it only affects the performance of (read and write)
queries.
Writes go to the primary data and all of the other data copies are derived from it.
The other copies only serve read requests.
TODO: address that some systems support writes to a view.

\subsubsection{Partitioning and Secondary Indexes}

The partitioning schemes discussed in \ref{sec:partitioning} rely on a key-value data model.
Secondary indexes do not neatly map to the partitioning technique:
a secondary index usually does not uniquely identify a data item, but rather provides a way of searching for occurrences
of a particular value.

There are two main approaches to partitioning a secondary index:
document-based partitioning and term-based partitioning.

The terminology used in the rest of this section comes from the literature of full-text indexes (a particular kind of secondary index):
a document is a self-contained piece of information, that is composed of terms.

\bigskip

\noindent
\textbf{Partitioning Indexes by Document.}
In this approach, each partition is separate:
each partition maintains its own secondary indexes, covering only documents in that partition.
A document-partitioned index is also known as a \textit{local index}.

When this approach is used, each database write (adding, removing, or updating a document) is handled only by the
partition that contains the corresponding document.
However, reading from a document-partitioned index requires a scatter/gather approach:
sending the query to all partitions, and combining the returned results.
This can make index lookups quite expensive.
Even if index lookup requests are sent to partitions in parallel, scatter/gather is prone to tail latency amplification,
as the total latency depends from the latency of the slowest index partition.

This approach is widely used: MongoDB, Riak \cite{riakv:secondaryindexes}, Cassandra \cite{cassandra:secondaryindexing}
Elasticsearch \cite{elastic:docrouting}, Solr \cite{solr:indexsharding}.

\bigskip

\noindent
\textbf{Partitioning Secondary Indexes by Term.}
An alternative approach is to construct a \textit{global index} that covers data in all partitions.
A global index, however, also needs to be partitioned, as storing it on one node would likely become a bottleneck.

To partition a global index, the indexed terms can be used as the partition key (thus the term \textit{term-partitioned}
index).
Same as in base data partitioning, the index partitioning scheme can use the terms themselves, which can be useful for
range scans, or a the terms' hashes, which results to a more even load distribution.

The advantage of a term-partitioned index is that it can make reads more efficient:
rather than requiring a scatter/gather over all partitions, a lookup for a given term only needs to make a request to the
partition containing that term.
The downside of this approach is that writes are more complicated and slower:
a write to a single document may affect multiple partitions, the document's terms may be on different partitions.

DynamoDB supports both global and local secondary indexes \cite{dynamodb:secondaryindexes}.
Global indexing has also been used in the research systems such as SLIK \cite{kejriwal:slik} and Diff-Index \cite{tan:diffindex}.

\bigskip
TODO: discuss routing on the two approaches.

TODO:
% https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GSI.html
% When you put or delete items in a table, the global secondary indexes on that table are updated in an eventually consistent fashion. Changes to the table data are propagated to the global secondary indexes within a fraction of a second, under normal conditions. However, in some unlikely failure scenarios, longer propagation delays might occur. Because of this, your applications need to anticipate and handle situations where a query on a global secondary index returns results that are not up to date.

\bibliographystyle{plainnat}
\bibliography{refs}