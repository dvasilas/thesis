\begin{tcolorbox}
\textbf{Outline Description - Internal}
The goal of this chapter is to prepare the ground so that the reader has the mental framework needed to understand the
rest of this document.

This includes:
\begin{itemize}
  \item Implicitly establishing the terminology to be used throughout the document.
  \item Establishing a ''world view'' by describing the system and data model that we consider, and the assumptions that
  we make
  \item Establishing concepts that will guide our design decisions in the following chapters (performance metrics etc.)
\end{itemize}
\end{tcolorbox}

\section{Models}
We consider a data serving system with a two-tiered architecture: a data storage tier and a query processing tier.

\begin{itemize}
\item The data storage tier is responsible for providing access to data.
We use the terms \textit{storage system} or \textit{data store} for the system that implement this tier, and the terms
\textit{base data} or \textit{corpus} for its data.
\item The query processing tier is responsible for providing the functionality to identify and retrieve data using
queries on secondary attributes (Section~\ref{subsec:query_prcessing_tier}).

We use the terms \textit{query engine} or \textit{query (processing) system} for the system that implements this tier.
\end{itemize}

Disaggregating query processing from the storage engine is an approach used by various systems and cloud
services such as Amazon Athena \cite{aws:athena}, Aurora \cite{aws:aurora}, and Google BigQuery
\cite{google:bigquery}.
In these systems, query processing is performed by a query engine independent from the storage system.

This model provides several benefits:
\begin{itemize}
  \item Storage and query processing resources can scale independently (elasticity).
  \item It enables on-demand, short-lived queries on already existing data without the need to migrate data.
  \item It enabling cloud providers to implement fine-grained pricing for querying services.
\end{itemize}

In this work, we focus on the design of the query processing tier and consider the data storage tier as ``imposed'':
we consider the data storage tier's functionalities, guarantees, and data distribution schemes as input parameters in
our design.

One of our design goals
(TODO: link to design goals in the next chapter)
is that the query processing tier should be agnostic of the data storage tier.
A query system should be able to interoperate with multiple different data storage tier implementations.
To achieve that, we model the interconnection between tiers as a set of well-defined APIs, which we describe
in detail in the following section.


\subsection{Data storage tier}

The data storage tier is a broad abstraction that can include any system that can be used to store and retrieve data.
This can include databases, file systems, cloud object storage systems.

As described above, in this work we view this tier as an external, underlying system that our design can build upon.
However, any efficient query processing tier design needs to take into account the properties and characteristics of the
data storage tier, most importantly its data distribution scheme.
To address that, we adopt a less broad data storage tier definition.
More specifically, we model a data storage tier as a federation of geo-replicated storage systems.
In the following Section, we present in detail our data storage tier model.


\subsubsection{System model}
The data storage tier is implemented by a storage system (a database, file system or cloud storage system) or a
federation of multiple, potentially heterogeneous storage systems.
Each system is responsible for storing a dataset $D$.
In a federated system, the dataset of each storage system is independent, but the application logic may implement
replication across different systems (for example an application that replicates data across multiple cloud providers).
In addition, storage systems implement replication:
each storage system maintains one or more full replicas of its dataset, and may also maintain partial replicas.
Finally, replicas are sharded: each replica partitions its data in non-overlapping parts, and a shard is responsible
for a part of the data.

We model the infrastructure on which the data storage tier runs as a collection of \textit{sites}.
A site is a group of nodes (servers, user devices) with the following characteristics:
\begin{itemize}
  \item Network communication latency between nodes in different sites is significantly higher (typically an order of
  magnitude higher) \cite{pbailis:hats} compared to communication latency within a site.
  \item Network resources across sites are more limited and costly across sites.
  This is reflected in the pricing for cross-region data transfer in public cloud platforms.
  Using the AWS Pricing Calculator \cite{aws:costcalc} we see that data transfer to different AWS data centers
  (regions) costs double the price of intra-DC data transfer (0.02 and 0.01 USD per GB respectively).
\end{itemize}

A site can correspond to a data center, a group of servers serving as an edge Point of Presence \cite{google:infra}, or
a group of user devices in close proximity (in the same room or building).


\subsubsection{Data model}
The corpus dataset is a collection of \textit{data items}, organized in \textit{tables}.
We use the term \textit{data item} to refer to the unit of stored data:
Depending on the storage system, a data item may correspond to a file, and object, or a database record.
Tables may be organized in a hierarchical structure (file system repositories), a flat namespace (object store buckets),
or a relational schema.

A data item is composed of a primary key, a set of attributes, and optionally a value.
The primary key can be used to efficiently identify and retrieve the data item, without requiring a scan.
Attributes are key-value pairs: each data item is associated with a map of attribute keys and values
$\{AttrKey: AttrVal\}$.
We do not assume a strict schema for attributes: the attributes of each data item are independent of the attributes of
others.
Finally, we consider the data item's value as a blob of binary data.

This data model can express the data model of multiple different types of storage systems:
\begin{itemize}
  \item Object stores, such as AWS S3: \\
  The data storage tier can be implemented by an object store.
  In that case, data items correspond to objects and tables to buckets.
  In addition, a data item's value corresponds to the object's content, and attributes correspond to object
  tags \cite{awss3:tagging}.
  \item Wide-column stores, such as Amazon DynamoDB, Google's Bigtable or Apache Cassandra: \\
  In a data storage tier implemented by a wide-column store:
  \begin{itemize}
    \item In both data models data is organized in tables.
    \item Data items correspond to table rows and attributes correspond to columns.
    \item Data items' values are empty.
  \end{itemize}
  \item Relational databases: \\
  Similarly to the wide-column data model, the relational model can be expressed by representing table records as data items,
  and columns as attributes.
  The difference between the two models is that while in the relational model each table has a schema that defines the
  names and format of its columns, in the wide-column model column names and format can vary from row to row in the same
  table.
  \item Document stores, such as MongoDB: \\
  The described data model is partially compatible with the document store data model.
  In the case of a data storage tier implemented by a document store, tables correspond to document collections, and
  data items correspond to documents.
  A document's identifier can be represented as a data item's primary key, while document attributes can be represented
  as attributes.
  However, the described data model does not model complex attribute types such as lists and maps which are supported by
  document stores.
  \item File systems: \\
  In a data storage tier implemented by a file system, data items correspond to files and tables correspond to file
  system repositories.
  A data item's primary key corresponds to the corresponding file's name, the value to the file's content, and attributes
  correspond to extended file attributes.
\end{itemize}

This general data model, which is able to express different existing data models, caters to the design goal mentioned
above:
Allowing the query processing tier to be agnostic of the underlying data storage tier, and be compatible with different
storage tier implementations. \\

\noindent \textbf{Timestamps} \\
We assume that objects are ''versioned``.
Each object is associated with a timestamp, which is one of it's attributes.
A timestamp can be implemented by any data type that provides a comparison operator which can be used to establish an
at least partial order between timestamps, such as Unix time or vector timestamps.


\subsubsection{Data storage tier API}

The data storage tier exposes at least one of the following APIs:
\begin{itemize}
  \item An API for iterating over the corpus data (List).
  \item An API for subscribing to notification for changes to the corpus data (Subscribe).
  \item An API for querying the corpus data (Select).
\end{itemize}

\noindent
\textbf{API 1: List}

\noindent
This API provides a mechanism for retrieving the primary key and attributes of all objects in a given table:

$List(Table, [Timestamp_{low}, Timestamp_{high}))$ $\rightarrow$ $[ListResponse]$

\noindent
Given a table name ($Table$) and a range of timestamps ($[Timestamp_{low}, Timestamp_{high})$),
$ListResponse$ contains all data items in $Table$ with $Timestamp_{low} \leq Timestamp < Timestamp_{high}$.
Each data item in $ListResponse$ is represented as a tuple $(ID, \{AttrKey: AttrVal\})$, containing the data item's
primary key ($ID$), and attributes ($\{AttrKey: AttrVal\}$).

$ListResponse$ may be implemented in different ways, such a single response containing a set of
data items, or a stream in which each data item is sent as a record, or an iterator in which calling a $Next()$ method
returns the following data item.
Finally, We don't assume any ordering in $ListResponse$.

The $List$ API may be provided as an explicit API method or implemented as a combination of a \textit{list} and a
\textit{read} (get) operation.

Depending on its versioning mechanism, the storage system implementing the data storage tier may not support the
listing API for any range of timestamps.
For example, in a storage system that does not provide multi-versioned storage, $List$ will return the latest version of
each data item.
For simplicity, we assume the $List$ API as specified above.
In Section
TODO
we describe how our design can cater for a $List$ API without support for Timestamp ranges.
\\

\noindent
\textbf{API 2: Subscribe}

\noindent
This API provides a mechanism for subscribing to notification for updates to data items in a given table:

$Subscribe(Table, [Timestamp_{low}, Timestamp_{high}))$ $\rightarrow$ $[SubscribeResponse]$

\noindent
Given a table name ($Table$) and a range of timestamps ($[Timestamp_{low}, Timestamp_{high})$),
$Subscribe$ initiates a stream called $SubscribeResponse$.
For each update performed in a data item $d$ in $Table$, creating a new version of $d$ with
$Timestamp_{low} \leq Timestamp < Timestamp_{high}$, a record is sent in $SubscribeResponse$.
$ListResponse$ records have the form $(ID, \{AttrKey: (AttrVal_{old}, AttrVal_{new})\})$:
each record contains the update data item's attributes before and after the update.
If an operation updates more than one data items, then a $ListResponse$ record is sent for each updated
data item.
If an attribute is created by the update, then its old value has the special value $null$.
Conversely, if an attribute is deleted by the update, then its new value has the $null$ value.

Various systems provide mechanisms that can be used to implement the $Subscribe$ API.
Examples include triggers in traditional database management systems \cite{mariadb:triggers}, and event notification
mechanisms in cloud storage services \cite{awss3:notifications}.
\\

\noindent
\textbf{API 3: Select}

\noindent
This API provides a mechanism for identifying data items based on their attributes:

$Select(Table, Predicate, [Timestamp_{low}, Timestamp_{high}))$ $\rightarrow$ $[SelectResponse]$,
where $Predicate$ is a map containing attribute keys and ranges:
$\{AttrKey: [AttrVal_{low}, AttrVal_{high})\}$.

Given a table name ($Table$), a range of timestamps ($[Timestamp_{low}, Timestamp_{high})$), and
a predicate consisting of attributes keys and ranges of values
($\{AttrKey: [AttrVal_{low}, AttrVal_{high})\}$), $Select$ returns $SelectResponse$.
$SelectResponse$ contains all data items in $Table$ that have all attributes contained in $Predicate$ and
their values are within the ranges specified in $Predicate$.

$Select$ can be expressed as an SQL query with the form: \\
\noindent
$SELECT$ $AttrKey_1$, $AttrKey_2$, ..., \\
$FROM$ $Table$ \\
$WHERE$ \\
$AttrKey_1$ $IS$ $NOT$ $NULL$ $AND$ $AttrVal_{low}$ $\leq$ $AttrKey_1$ $<$ $AttrVal_{high}$
$AND$ $AttrKey_2$ $IS$ $NOT$ $NULL$ $AND$ $AttrVal_{low}$ $\leq$ $AttrKey_2$ $<$ $AttrVal_{high}$
$AND$ ... \\
$AND$ $Timestamp_{low}$ $\leq$ $Timestamp$ $<$ $Timestamp_{high}$

$Select$ may be provided as a subset of a more expressive query language, such as in relational database
systems that support a full SQL query language. \\

\noindent
As we further discuss in Chapter
TODO,
the two tiers interoperate through these well-defined APIs.
This allows the query processing tier to be agnostic of the data storage tier, and compatible with any storage system
that exposes the described APIs.
As an example, the query processing tier can work on top of a streaming system that does not persist data but exposes
the $Subscribe$ API.

For the rest of this document, we assume for simplicity that the data storage tier exposes the $List$ and $Subscribe$
API as described here.
In Section
TODO,
we discuss the implications of the data storage tier exposing only one of the APIs to the query processing tier
functionality.
In addition we discuss the implications of $List$ and $Subscribe$ not supporting a range of timestamps but rather
returning results about the most recent timestamp, and how the query processing tier can make use of the $Select$ API.

\subsection{Query processing tier}
\label{subsec:query_prcessing_tier}
The design decisions and trade-offs involved in the design of the query processing tier is the main focus of this work.
In this Section we present an overview of the query processing tier's role and functionality.
The following Chapters present our query processing tier design in more detail.

The query processing tier is responsible for providing attribute-based data retrieval:
Identifying and retrieving data items based on queries on their attributes.

As query language, we consider a subset of SQL that supports expressions of the form: \\

\noindent
$SELECT$ $projection$ $FROM$ $Table$ $WHERE$ $predicate$
\noindent
where
\begin{itemize}
  \item $projection$ is a list of attributes, $AttrKey_1$, $AttrKey_2$, ..., $AttrKey_N$.
  \item $predicate$: has the form: \\ $rangePredicate_1$ $AND$ $rangePredicate_2$ AND ... AND $rangePredicate_N$, \\
  where $rangePredicate_i$ an expression of the form $AttrVal_{low}$ $\leq$ $AttrKey$ $<$ $AttrVal_{high}$.
\end{itemize}

Given a query $Q$ = ($projection$, $table$, $predicate$)
and a data item $d$ = ($table$, $id$, $attributes$), $d$ satisfies $Q$ if:
\begin{itemize}
  \item $Q.table$ = $d.table$: the data item belongs in the table referred by the query, and
  \item $\forall$ ($AttrVal_{low}$ $\leq$ $AttrKey$ $<$ $AttrVal_{high}$) $\in$ $Q.predicate$:
  $attrKey$ $\in$ $d.attributes$ and $AttrVal_{low}$ $\leq$ $AttrVal$ $<$ $AttrVal_{high}$:
  the data item contains all attributes included in the query's predicate, and their values are within the ranges
  specified by the predicate.
\end{itemize}

$Predicate$ may contain expressions that refer to the $Timestamp$ predicate.
In that case, a data item satisfies $Q$ if, in addition to the above conditions, its $Timestamp$ satisfies the
$Timestamp$ -related expressions in $predicate$.
If no $Timestamp$ -related predication is given, then only the latest version of each data item is considered for the
query.

We define the set of data items that satisfy a query $Q$ as $Q_r$.
In the ideal case, $Q$'s response is $Q_r$, however, as we explain in the following section a query response may
differ from $Q_r$. \\

\noindent
\textbf{Derived data} \\
Query systems often maintain data such as indexes, materialized views, and caches.
We refer to this data as \textit{derived} data.
Derived data, in the general case, is obtained by performing a computation over the base data.
As a result, this state needs to be updated to reflect changes to the base data.
For indexes and materialized views this involves updating their entries according to the base data changes.
For caches this involves invalidating obsolete cache entries.

As we describe in the following section, inconsistencies between base derived data is the main factor
resulting to a query response being different from $Q_r$.


\section{Query processing system performance evaluation}
\label{sec:requirements}

An important first step in the process of designing a query processing system (and any system in general) is determining
the factors and metrics that will be used to evaluate how well the design achieves its goals.

The aspects of a query processing system's performance can be categorized in two groups:
\textit{efficiency} and \textit{effectiveness} \cite{buttcher:informationretrieval}.
Efficiency can be measured using metrics such as response time, throughput, and scalability.
Effectiveness is a measure of how well a query processing system achieves its intended purpose.
It involves metrics such as precision and recall.

Finally, two other important factors in the design of query processing systems are availability and operational cost.
Availability is important due to the negative effects of downtime in user serving systems.
It is especially relevant in the design of distributed systems due to the many different faults that can impact the
operation of a distributed system \cite{kleppmann:designing}.
Cost ...

\subsection{Evaluating Efficiency}

The most visible aspect of efficiency is the \textit{response time} experienced by a user between issuing a query and
receiving the corresponding response.
Since the query system needs to support many simultaneous users, \textit{query throughput}, measured in queries served
per unit of time, is an important performance metric for the query processing system.
In addition, as response time is the measure that directly affects user experience, an important efficiency metric is
how response time scales with query throughput.
This measures whether the system can maintain low query response time for individual users as its load increases.
The relation between response time and query throughput, together with the throughout of an individual user, as the
total system throughput increases, characterize the system's \textit{scalability}.

\subsubsection{Response time}
Response time - the amount of time between making a request and receiving the corresponding response -
is among the most important metrics for the quality of a user-facing service.

A number of studies and experiments have studied the effects of response time to user experience.
Results show that response time is among factors that have the largest effect users' subjective perception of the
quality of a system.
Users have been shown to perceive websites that load faster as more interesting \cite{ramsay/retrievaltimesinvestigation}.
On the other hand, long response times increase user frustration \cite{ceaparu:userfrustration} and even compromise
user's conceptions of the security of the system \cite{bouch:qualityeyebeholder}.

Industry reports have indicated that even small increases in user-perceived response times can result in drops in web
traffic, and therefore sales.
Experiments by the Google and Bing search engines have shown that loner page loading times have a significant impact on
metrics such as time to click, repeated site usage, and queries per visit \cite{schurman:rerformanceuserimpact}.
A study from Akamai on the impact of travel site performance on consumers showed that more than half of the users will
wait three seconds or less before abandoning the site \cite{akamai:travelsiteperformance}.
Finally, a comparison shopping service (Shopzilla) has reported that a website re-engineering project that achieved a
speedup in page load time from 6-9 seconds down to 1.2 seconds resulted in 25\% increase in page views and 5-12\%
increase in revenue \cite{dixon:shopzillasiteredo}.

\subsection{Evaluating Effectiveness}

Effectiveness is a measure of how well a query processing system achieves its intended purpose.
In the field of information retrieval, the key notion linked effectiveness is \textit{relevance}
\cite{buttcher:informationretrieval}:
Given a user's information need represented by a search query, each document in a given a document collection is either
relevant or non-relevant with respect to the information need.
The two most used effectiveness measures in information retrieval systems evaluation are recall and precision:
\begin{itemize}
  \item Recall is the fraction of relevant documents contained in the query result.
  It is affected by false-negatives: not including relevant documents in the query result.
  \item Precision is the fraction of relevant documents among the documents contained in the query result.
  It is affected by false-positives: including non-relevant documents in the query result.
\end{itemize}

The difference between information retrieval query model, and the one that we consider in this work is that here there
is no notion of a ranking function.
In information retrieval relevance is a spectrum: documents can be more or less relevant to a given query.
Here, relevance is binary: a data item is either relevant (satisfies the given query) or it is not.
However, as mentioned in Section \ref{subsec:query_prcessing_tier}, similarly to information retrieval, query results
can include non-relevant data items, or not include relevant data items.
Therefore we argue that the recall and precision can be used as metrics to evaluate the effectiveness of the query
processing tier.

As mentioned in Section \ref{subsec:query_prcessing_tier}, a factor that can affect query effectiveness is the
consistency between base and derived data.
Traditional database systems, keep derived data consistent with base data by updating them in the critical path
of each base data update.
However, in systems that implement asynchronous (lazy) derived data maintenance policies \cite{tan:diffindex,
qi:secondaryindexconsistencyanalysis, shukla:schemaagnostic} derived data can become stale with respect to base data.
This can result in both false-positives and false-negatives, affecting the recall and precision of these systems.

We use the notion of \textit{freshness} to refer to the measure of inconsistency between base and derived data due to
asynchronous derived data maintenance.

A number of metrics for measuring data freshness have been proposed in the literature \cite{bouzeghoub:datafreshness}:
\begin{itemize}
  \item \textbf{Currency} measures the time between a change in the source data, and that change between reflected in
  the derived data.
  In caching systems, the terms recency \cite{bright:latencyrecency} and age \cite{cho:dbfreshness}
  have been used to describe this metric.
  \item \textbf{Obsolescence} measures the number of updates to source data since derived data was last updated.
  Work on query systems has defined the \textit{obsolescence cost} \cite{avigdor:obsolescent}, of a query to represent
  the penalty of basing a query result on obsolescent materialized view.
  This cost is computed as a function of the number of insertions, updates, and deletions that cause deviation between
  the materialized view and and the base table.
  \item \textbf{Freshness-rate} measures the percentage of derived data entries that are up-to-date with the source
  data.
  This metrics has been used to quantify the freshness of web pages \cite{labrinidis:balancingperfomancefreshness} and
  local databases copies \cite{cho:dbfreshness}.
\end{itemize}

\subsection{Other aspects of query processing system design}

\subsubsection{Availability}
The importance of availability becomes apparent when considering the negative effects of service downtime.

A study on user behavior in the Web \cite{nah:waitingtime} found that users abandon a non working hyperlink after
5-8 seconds.

Operators of global services understand that "even slightest outage has significant financial
consequences and impacts customer trust" \cite{deCandia:dynamo}.
A service 49 minute service outage in January 2013 cost Amazon an estimated \$4 or more in lost sales
\cite{infoworld:cloudoutages}.

\subsubsection{Operational Cost}
Operating a query processing system requires computation, memory, network and storage resources.
When the system is deployed on dedicated infrastructure, the monetary cost of these resources is equivalent to the cost
of owning and operating the infrastructure.
Nowadays that services our more and more deployed on cloud infrastructure with fine-grained resource provisioning and
billing mechanisms, system operators have more fine-grained control over the system's resource usage and thus its
monetary cost.
Given a billing model, a system's operational cost can be calculated using its resource utilization.

The operational cost can be modeled as:
\begin{itemize}
  \item \textbf{Per-time unit cost}: Given a model for the system's load, the system's resource utilization over a
  period of time can be calculated.
  \item \textbf{Per-query and per-update cost}: The resources used to process a given query or a given base data udpate.
\end{itemize}

\bibliographystyle{unsrt}
\bibliography{refs}