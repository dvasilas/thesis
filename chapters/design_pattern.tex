
We have so far established that query processing involves requirements that are in tension and create trade-offs.
As a result, there can be no general-purpose solution to query processing.
Rather, achieving efficient query processing requires the ability to \textit{tune} the system to the requirements
and characteristics of specific use cases.
Existing query processing systems provide some tunning capabilities, for example index and materialized view selection.

However, as discussed in Section~\ref{sec:topology_patterns}, in modern, internet-scale systems in which clients and data
are geo-distributed,
design decisions about \textit{placement} of derived state (indexes, caches, materialized views) involve additional
trade-offs and magnifies the effects of existing trade-offs.
Existing query processing systems do not provide mechanisms for controlling the placement of derived state.

The design of a geo-distributed query processing system presents several unique design issues:

\bigskip
\noindent
\textbf{Tunability.}

\noindent
Achieving efficient geo-distributed query processing requires the ability to adjust the query processing system
to the workload characteristics, data and access distribution patterns, and requirements of specific use cases.
An efficient geo-distributed query processing system should provide tunning mechanisms along the following dimensions:

\begin{itemize}
  \item \textit{Flexible placement of derived state.}
  In geo-distributed environments, communication latency between sites is an order of magnitude higher than
  communication latency within a site.
  The use of secondary indexes and materialized views in this context, involves a trade-off between the requirements
  of minimizing the inter-site communication in the read path, and in the write path.
  We have have analyzed the implication of this trade-off in section~\ref{sec:topology_patterns}.
  Therefore, an efficient query processing system requires fine-grained control over the placement of derived state
  across the system.

  \item \textit{Flexible placement of query processing computations.}
  For the same reasons, achieving efficient geo-distributed query processing requires the ability to control the
  placement of query processing computations in order to minimize the amount of inter-site communication.
  For example, the system can accelerate the execution of a join operation between two sets of data items located in different sites
  by performing the join in the site in which the larger set is located.

  \item \textit{State maintenance scheme.}
  Keeping derived state up-to-date with the corpus involves a trade-off between
  the overhead incurred to write operations and the consistency between derived state and corpus data (section~\ref{sec:sync_async_maintenance}).
  Updating the derived state synchronously
  ensures that it is strongly consistent with the
  corpus, but introduces additional work to the write path --- potentially involving inter-site communication.
  Conversely, performing this task asynchronously reduces the impact to write operations,
  but allows derived state to be stale relative to the corpus.
  Which maintenance scheme is better suited to a specific use case depends on its workload characteristics (query or write-heavy), and consistency requirements.

  \item \textit{Index and materialized view selection.}
  As we described in section~\ref{sec:read_write_path}, the choice of which secondary indexes and materialized views to
  materialize involves a trade-off between work on the read path on the one side,
  and one the other side work on the write path as well as the resource required for maintaining derived state.
  Therefore, the query processing system needs to enable configurable index and materialized view selection.

  \item \textit{Caching.}
  As we described in section~\ref{sec:read_write_path},
  caching, similarly to materialized views, can be viewed as a point in the design space defined by the read and write
  work framework.
  Therefore, index and view selection mechanisms should also include decisions about caching.

    % \item State partitioning scheme:
    % Similarly, the partitioning scheme used for secondary indexes and materialized views should be configurable in a per
    % index/view basis.
\end{itemize}

\medskip
\noindent
\textbf{Independence from corpus distribution schemes.}

\noindent
Geo-distributed applications feature a variety of diverse data distribution schemes.
Examples include full and partial data replication across data centers, geo-partitioning, and federated systems.
An effective geo-distributed query processing system should not be limited to a specific data distribution scheme.

\bigskip
\noindent
We argue that traditional monolithic query processing system architectures cannot provide the flexibility required
to address these requirements --- notably enabling flexible derived state placement.
In this work we take a different approach.
We propose a framework for constructing query processing systems in a case-by-case basis.
The key idea is a modular, composable query processing architecture:
application developers can construct and deploy query processing systems by assembling composable building blocks that
encapsulate primitive query processing tasks.
In this chapter,
we focus on the \textit{mechanisms} required for enabling a modular and composable query processing system architecture.

% We show how the proposed approach translates tunning mechanisms, such as index selection, to design decisions about
% the query processing architecture's topology, and how modularity enables flexible placement of derived state and query processing
% computations.

% Decoupling between storage architecture and query processing architecture.
% The design pattern should not be based on architecture, mechanism or interface of a specific data storage tier.
% Instead, it should enable a query processing system to work as a middleware systems on top of an existing database system.


% structured approach to tunning query processing systems that unifies the tunning dimensions available in existing systems with flexible derived state placement.

\section{Overview and design rationale}
\label{sec:design_rationale}
Our first design decision is to decouple the query processing architecture from the storage architecture.
We design the query processing system as a \textit{middleware system} that communicates with the storage tier through
well-defined interfaces.
This provides the query processing system with the flexibility required to support diverse data distribution schemes.
Moreover, it allows the query processing system to be compatible with different storage systems,
which is required in order to support federated query processing.

\medskip
\noindent
The second decision is to not focus on the design a \textit{specific} query processing system,
but rather a \textit{framework} for constructing query processing systems in a case-by-case basis.
% using \textit{assembly-based modularity} \cite{leclercq:dream, bouget:pleiades}.
The proposed framework provides a set of composable building blocks that encapsulate simple query processing tasks
such selections, aggregations, and joins, as well as derived state structures, including secondary indexes, materialized views.
These building blocks can be composed into modular query processing architectures.
% We believe that modularity is essential for achieving the flexibility required to provide the tunning mechanisms described above.
Moreover, we design the building blocks as independent components with well-defined boundaries.
Because of that, their placement across the system is orthogonal to their functionality.
This is key insight for achieving flexible state and computation placement.

% addresses the requirement for

% Moreover, we use modularity to translate tunning mechanisms, such as index and view materialization, caching, and derived state partitioning,
% to \textit{composition choices}.
% For example, adding a caching layer to an existing query processing system can be done by extending an existing
% architecture with additional ``caching'' building blocks.

% Application developers can construct query processing systems by composing

% We argue that assembly-based
%  traditional monolithic query processing system architectures cannot provide the flexibility required
% to address these requirements --- notably enabling flexible derived state placement.


% In that way,
% Moreover, design decisions about the placement of derived state and query processing computations translate to
% decisions about the placement of building blocks.

% the query processing architecture's building blocks separate interface from implementation.
% Because the query processing system's components communicate through composable interfaces,
% they can be flexibly placed across the system infrastructure.
% As a result, a given query processing system architecture can support multiple different component placement schemes.

\bigskip
\noindent
Our design is based on a set of \textbf{observations} about the functionality and semantics of query processing systems.
We use these observations as a basis for breaking down the functionalities of a query processing system into a
set of \textit{primitives}.
We unify the semantics of these primitives under a component that can be used as the building block
of a composable, modular query processing architecture.

In order to describe these observations, we introduce the example of a news aggregator application.
In that application, users post and vote on news stories.
The application stores individual votes for stories in a votes table.
It uses a materialized view to compute the vote count of each story and join it with the rest of the story's records,
as shown in Listing~\ref{lst:observations_example_1}.

\begin{lstlisting}[
    caption={Definition of a materialized view that computes the vote count of each story and joins it with
    the rest of the story's attributes.},
    label={lst:observations_example_1}
]
TABLE stories (id int, title text, url text)
TABLE votes (story_id int)

VIEW stories_with_voteCount
  SELECT id, title, url, vote_count
  FROM stories
  JOIN (
    SELECT story_id, SUM(*) as vote_count
    FROM votes
    GROUP BY story_id
  )
  ON stories.id = votes.story_id
  WHERE stories.id = ?
\end{lstlisting}

Moreover, this materialized view is partitioned with the partition by document approach, using the $story_id$ as partitioning key.

\begin{figure}[H]
  \centering
    \includegraphics[width=\textwidth]{./figures/design_pattern/running_example.pdf}
    \caption{Conceptual depiction of the news aggregator application query processing architecture.}
    \label{fig:running_example}
\end{figure}


Figure~\ref{fig:running_example} depicts a simplified version of the application's query processing architecture.
An aggregation and a join operator incrementally compute the $stories_with_voteCount$ view as new stories and votes are added.
The view is partitioned among multiple view partitions.
A partition manager is used to manage access to the view partitions.

We use this example as a reference for discussing our observations on the semantics of query processing systems.

\vspace{12pt}
\noindent
\textbf{Breaking down query processing in basic primitives.}

\noindent
First, the functionality of a query processing system can be divided into three parts:
\begin{itemize}
  \item The execution of relational algebra operations.
  In the news aggregator example the component that calculate the $vote\_count$ per story,
  and perform the join with the stories table are relational operators.
  Other examples of relational operators are selections and projections.

  \item Maintaining derived state structures.
  The materialized view partitions in the example consists derived state structures.
  Other examples include secondary indexes and caches.

  \item ``Routing'' functionalities.
  We can describe the functionality of the partition manager in the example we the term routing.
  This component is responsible for forwarding queries to the view's partitions and combining the return responses.
  There are other functionalities of query processing system component that can be categorized as routing,
  such as load balancing, and the federation of independent corpora.
\end{itemize}

\vspace{12pt}
\noindent
\textbf{Encapsulating query processing primitives to system components with service semantics.}

\noindent
Second, each of these types of functionalities can be encapsulated by an \textit{independent system component} with microservice semantics:
the component provides its functionality as a service through a ``service interface'';
other components can request the component's functionality by invoking its interface.
In the news aggregator example,
we can model the partition manager as a microservice that abstract the underlying architecture,
exposing only an interface for service queries.
Similarly,
we can implement each view partition as an independent component that exposes an interface encapsulating the view's query method.
The partition manager forwards a given query to each view partition by invoking its interface.
Finally, we can also apply this to components with relational operator functionalities:
We can model the join operator as a component that provides its join operation functionality as a service.
Each view partition invokes the join operator's interface using the view definition.

Next, we examine the service interface's response for the three types of query processing functionalities.
% In chapter~\ref{ch:models} \todo{MUST HAVE: consistency with model chapter}, we have defined the corpus as a collection of a data items
% organized in tables;
% a data item is composed of a primary key, a set of attributes, and, optionally, a content value.
% In the stories table, a story record is data item is a story, with $story\_id$, $title$ and $url$ being its attributes:
% \begin{itemize}
  % \item

  \medskip
  \noindent
  \textbf{Relational operators} \textit{transform} an input set of attribute tuples, to an output set of tuples:
    \begin{itemize}
    \item A projection operator discards one more attributes.
    \item A join operator receives two sets of input tuples.
    Its output is a set of tuples containing a combination of the attributes in the input tuples.
    In the example, the join operator extends the story's attributes by adding the $vote\_count$ attribute.
    \item An aggregation operator (such as count or sum) generates output tuples that represent groups of input tuples.
    These output tuples contain the attributes of input tuples, extended with an additional attribute that represents the
    result of applying a \textit{function} over the tuples in a group.
    In the example, the count operator's response is a set of tuples,
    each containing a unique $story\_id$, extended with the $vote\_count$ attributes
    which is the result of applying the count function to the tuples of each group to input tuples with common $story\_id$.
    \end{itemize}
  We can unify these transformations by modeling the output of a relational operator component as a tuple of attributes.

  % \item
  \medskip
  \noindent
  \textbf{Derived state structures} accelerate read access to a set of tuple attributes,
  but not perform any transformations.
  In the news aggregator example, the view partitions pre-compute the results of the join and count operation.
  Therefore, the response to an invocation a view partition's interface is the same as the response of the join operator.

  \medskip
  \noindent
  \textbf{Routing operators} either forward the responses of other components, or combine them by merging
  multiple input sets of tuples to a single output set.

  % \end{itemize}

\bigskip
\noindent
Our third observation is that we can use a common model for the responses of all three types of query processing functionalities.
The response to the invocation of a components service interface is a set of tuples of attributes.
These attributes might be combinations of the attributes present in the data items of the corpus,
or the results of functions applied on those attributes.

\bigskip
\noindent
Combining the above observations,
we conclude that that query processing functionalities belonging in the three categories described above
can be encapsulated by a microservice-like component that provides its functionality through an interface.
The response to an invocation of this interface can be modeled as is a set of data items, each structured as a tuple of attributes.

% \begin{figure}[t]
%   \centering
%     \includegraphics[width=0.5\textwidth]{./figures/design_pattern/observations_partitioned_index.pdf}
%     \caption{Example of a simple document-partitioned index.}
%     \label{fig:observations_partitioned_index}
% \end{figure}

\vspace{12pt}
\noindent
\textbf{The query processing component's input port.}

\noindent
Our forth observation is related to the \textit{input} required for each query processing functionality type:
\begin{itemize}
  \item Indexes and materialized views expose a second interface for being updated to reflect changes to the corpus.
  In the news aggregator example, a materialized view partition receives receives from the join operator
  \textit{information about changes in the join operation result}.
  The following types of changes in the can occur in the join operation result:
  \begin{itemize}
    \item A new story has been created.
    \item The vote count for an existing story has changed.
    \item A story has been deleted.
  \end{itemize}

  % For example, an secondary index provides methods for adding and removing data items from posting lists.
  % This interface can be viewed as a mechanism for receiving notifications for corpus updates as input.
  % As we described in section~\ref{sec:sync_async_maintenance},
  % updating an index (or materialized view) to reflect an update to a data item $d$ consists of
  % (1) removing the information about the previous version of $d$ from the index, and
  % (2) adding the information about new current version.

  \item A cache, in the case of a cache miss, forwards the given query to a different component,
  and then receives the corresponding query result as input.

  \item As discussed above, relational operators receive a set of attributes tuples as input.
  Unary operators, such as selection, receive one set of tuples,
  and binary operators, such as joins, receive two sets.

  \item By definition, because of their functionality, routing components, receive the output of other components as input.
  The view partition manager in the example receives as input the responses of the index partitions to a given query.
\end{itemize}

We can categorize these inputs in two types:
\begin{itemize}
  \item An index or materialized view requires as input information about \textit{modifications} to the corpus.
  Moreover, the \textit{scope} of the input required by these components \textit{spans their entire operation lifetime}.
  In the example, index partitions need to \textit{continuously} receive information about story creation and deletion of
  stories and votes, in order to remain up-to-date with the corpus.

  \item Every other query processing functionality requires as input a information about the \textit{state} of the corpus.
  Moreover, contrary to indexes and materialized views, the \textit{scope} of this input is a \textit{single session}.
  In the example, the index partition manager receives as input the responses of view partitions for a specific query.
  Each query corresponds to a distinct set of input, tied to the specific query.
\end{itemize}

Our forth observation is that we can unify the two different \textit{type} and \textit{scope} input semantics.
First, we can represent both input scopes using streaming semantics.
The input required by an an index or materialized view can be viewed as a continuous stream of records encoding information about modifications to the corpus.
The input required by other components can be viewed as a stream of records that encode parts of the state of the corpus.
Using streaming semantics, we can couple the scope of an input to the lifetime of a stream.
The input to a view partition in the example is \textit{long-running} stream, the lifetime of which spans the lifetime of the partition.
An input to the partition manager is a stream that spans the processing of a specific query.

Second, we can represent both input types by structuring stream records as \textit{deltas}.
A delta consists of a base state, and information encoding a modification to that state.
Applying this to the news aggregator example,
we can represent the input to a view partition as a record with a base state part, and a modification part.
The base state part is a tuple $(story\_id$, $title$, $url$, $vote\_count)$.
The modification part may indicate that the story identified by the base state part is a newly created story,
that this story has been deleted,
or that this is an modified state of this story.

By omitting the modification part, the delta can also represent a part of corpus' state.
Applying this to the news aggregator example,
we can represent the input to the partition manager for a given query with the same record structure.
In this case, the modification part is empty.
The base state part represents the state of story that matches a given query.

Using this observation,
we extend the query processing component described above with a ``port'' for receiving an input stream consisting of records structured as deltas.

\vspace{12pt}
\noindent
\textbf{The relation between service interface and input port.}

\noindent
Our fifth observation is that the service interface and the input port of the query processing component,
are not independent from one another.
In the example, the input that the partition manager receives from an view partition
is the direct result of the partition manager invoking the interface of the partition.
Moreover, the stream of modifications that a view partition receives,
can be viewed as the result of an invocation of the join operators interface by the partition.

Guided by this observation, we extend the semantics of the query processing component as follows:
The response to an invocation of the component's service interface is a stream of records structured as deltas.

To enable this connection between service interface and input port, we distinguish two types of interface invocations.
A ``state'' invocation is evaluated \textit{a single time} against a specific state of the corpus and produces a set of
\textit{state} results.
In the example, the invocation of a view partition's interface by the partition manager is a ``state'' invocation.
It describes a query that is evaluated once against the state of the partition, and produces a set of results.
A ``persistent'' invocation is a long-running request that is re-evaluated upon each modification of the corpus.
In the example, the invocation of the join operator's interface by a partition is a ``persistent'' invocation.
It describes a query that is repeatedly re-evaluated each time join operator receives an input.

The second connection between input port and service interface is that the response to an interface invocation might be
the result of a transformation over the input.
This directly maps to the functionality of relational operators.
In the example, the join operator emits a new output record as a result of receiving an input record, either from the
stories table, or the count operator.

Expanding on this, we distinguish two mechanisms that query processing components use provide their exposed service:
\begin{itemize}
  \item A derived state component process requests by reading from its state (index, cache or materialized view).
  This is the case for index partitions in the example.

  \item Relational operator and routing components provide their functionality by performing a transformation over their inputs.
\end{itemize}

% can be viewed as the result of that component invoking the service interface of another component.

% We can illustrate this using the partitioned index example shown in Figure~\ref{fig:observations_partitioned_index}.
% To process a given index lookup,
% the partition manager forwards the lookup to the index partitions (assuming a document-partitioned index);
% each index partition responds with a set data items that correspond to the given lookup.
% Finally, the partition manager merges the received responses.

% When the index manager and index partition functionalities are provided by query processing components, as described above,
% this task can be described as follows:
% To process a given index lookup,
% the partition manager component invokes the service interface of index partitions.
% As a result, a stream is established between each index partition and the partition manager.
% Through each of these streams, the corresponding partition sends index lookup results to the partition manager.
% The partition manager receives index lookup results from the index partition as input streams through its input port.

\begin{figure}[H]
  \centering
    \includegraphics[width=0.4\textwidth]{./figures/design_pattern/observations_composition.pdf}
    \caption{Example of achieving higher-order functionality through composition of basic functionalities.}
    \label{fig:observations_composition}
\end{figure}

\vspace{12pt}
\noindent
\textbf{Composition of query processing components.}

\noindent
Our sixth observation is that while each individual component encapsulates a basic query processing functionality,
we can implement higher-level functionalities be \textit{composing} components.
This is depicted in Figure~\ref{fig:observations_composition}.
Components with basic functionalities, such as selection, project and join, are composed to execute a more complex task.

This a common technique used in existing query engines:
the execution of relational algebra expressions is represented as a dataflow computation performed by
a set of operators, each performing a basic functionality, connected in a directed acyclic graph \cite{cockroachdb:distsql, gjengset:noria}.
The graph's components are relational operators that receive one or more input streams,
perform an operation on them, and emit an output stream.
Graph nodes are connected so that the output stream of one operator is the input stream of another.

We can expand the composition property to also include  relational operator components as well as
derived state and routing components.
In the new aggregator example, we compose derived state components (view partitions), along with a routing component
(partition manager) to construct a partitioned materialized view.

\vspace{12pt}
\noindent
\textbf{Conclusion.}

\noindent
Combining the above, we define a \textit{system component} that combines properties of a streaming operator and a microservice.
Similarly to a streaming operator, the component receives one or more input streams, performs a computation over these streams,
and emits an output stream.
Similarly to a microservice, the component provides its functionality as a service through an interface.
The response to an invocation of this interface has streaming semantics.
Combining the two, any input stream is initiated as the response to the invocation of a component's service interface.
We call this component a Query Processing Unit (QPU).

\medskip
\noindent
An individual QPU provides a basic query processing functionality,
such as filtering an input stream based on a given condition, caching query results,
or routing query requests to index partitions.
Higher-order query processing functionalities are achieved by \textit{composing} multiple QPUs.

The mechanism that enables composition is that a query processing unit is able to invoke the service interface
of other units.
In that way, given a query, a QPU can perform ``sub-queries'' to other units,
and retrieve the corresponding responses as input.
It can then perform a computation on these ``partial results'' in order to compute the response to the given query.

We refer to the QPU's service interface as \textit{query interface},
and an invocation of that interface as a \textit{query request}.

% That QPU then receives the corresponding responses as an input stream.
% Therefore, every input stream that a QPU $Q_a$ might receive, is the output stream of another QPU $Q_b$
% More specifically, it is the response to an invocation of $Q_b$'s service interface by $Q_b$.
% We call the QPU's service interface, \textit{query interface},
% and its invocation a \textit{query request}.

\medskip
\noindent
The query processing unit is the building block of the proposed query processing system architecture.
A query processing system is a directed acyclic graph with QPUs as its vertices.
The graph's vertices represent potential query request --- response stream relations.
An edge from $Q_a$ to $Q_b$ indicates that $Q_a$ can send query requests to
--- and therefore establish input streams from --- $Q_b$.
We call $Q_b$ a \textit{downstream connection} of $Q_a$, and a query request sent from $Q_a$ to $Q_b$ a \textit{downstream query}.
The corpus is located the leaves of the graph (nodes with only incoming edges),
and client queries enter the graph through its root nodes (nodes with outgoing edges).

\medskip
\noindent
The \textit{computation model} of query execution emerges from the semantics of the query processing unit.
When a QPU at the root of the graph receives a query request,
is has two mechanisms available for processing it:
\begin{itemize}
  \item In the case of a stateful QPU it can process the given query, by reading from its internal state.
  For example, this is the case in a secondary index or materialized view component.

  \item It can establish input streams by invoking the interface one or more downstream connections,
  and perform a computation over these streams.
  For example, given a query, a QPU that implements a filter operator invokes the interface of a downstream connection.
  This initiates an input stream.
  The operator filters the input stream based on the condition specified by the query,
  and emits the item that satisfy the condition as the response stream.
\end{itemize}

These mechanisms are not mutually exclusive.
A cache QPU first reads from its internal state.
In case the results of the given query are not present in the cache,
the QPU forwards the the query to a downstream connection, and receives the results as an input stream.

When the downstream query mechanism is used,
this process is repeated at each QPU that receives a query request.
A client query, submitted at the root of the graph, progressively spawns sub-queries that flow downwards through
graph, defining a \textit{query execution sub-graph}.
Query results flow upwards through the edges of this sub-graph,
and are progressively combined to produce the final result.

Query execution is therefore \textit{decentralized}:
Each QPU takes \textit{local decisions} based on its functionality and a given query request.
The result of these local decisions is a distributed computation that performs query execution.


% and can interoperate with other QPUs by sending query requests to them.


% Representing a relational algebra query execution as a dataflow computation performed by a DAG of operators is a common
% technique in the state of the art \cite{cockroachdb:distsql, gjengset:noria}

% the execution of relational algebra operations can be expressed as dataflow computation performed by a
% directed


% This design pattern defines a \textbf{modular} and \textbf{composable} component-based query processing system architecture.
% We refer to the building block of this architecture as the

% A QPU is a \textit{system component} that combines properties of a streaming operator and a microservice.
% Similarly to a streaming operator, a QPU receives one or more input streams, performs a computation over these streams,
% and emits an output stream.
% Similarly to a microservice, a QPU provides its functionality by exposing an interface for receiving requests
% (called \textit{query requests})
% and can interoperate with other QPUs by sending query requests to them.
% The response to query request is a stream:
% every input stream that one QPU $A$ receives is the output stream of another QPU $B$, and is the response to a query request
% that $A$ has sent to $B$.

% \medskip
% \noindent
% A query processing unit can encapsulate a \textit{relational operator}.
% For example, a ``join operator'' QPU receives input streams that represent the tables to be joined,
% and emits an output stream that represents the results of the join operation on these tables.

% Moreover, a QPU can encapsulate a \textit{derived state structure}, such as an index, a materialized view, or a cache.
% For example, a ``secondary index'' QPU receives an input stream that represents notifications for updates to that table
% at the corpus.
% It maintains a secondary index data structure, which it stores as internal state.
% When it receives a query request, it reads from its internal state and emits the result as an output stream.

% Finally, a QPU can encapsulate component responsible for managing access to components of the query processing system, such as
% a partition or replica manager, or a load balancer.
% For example ``partition manager'' QPU, responsible for managing access to the partitions of a partitioned secondary index
% (each index partition being encapsulated by a QPU), sends query requests to the appropriate index partitions for a given
% query, and merges the resulting streams.

% Our key insight is that all three of the described QPU types --- relational operators, derived state, and routing operators ---
% can be generalized to a system component with common interface, and thus can be composed in order to implement higher-level
% query processing computations.



\section{The query processing unit: a building block for composable query processing architectures}

\subsection{The Query Processing Unit component model}
\label{sec:QPU_model}
In the previous section, we discussed our insights for unifying the semantics of the different types
of query processing tasks under a common component
that can be used as the building block of a modular query processing architecture.
Building on a set of observations,
we described an overview of the semantics of this component, called the query processing unit.

In this section, we formalize the query processing unit specification.
To achieve that, we introduce the query processing unit \textit{component model} (QPU Model for short).
The QPU Model defines the set of common properties that every query processing unit conforms to.
This includes the QPU's query interface, and the query request -- response stream semantics.
Using object-oriented programming terminology, the QPU Model can be viewed as an \textit{abstract class}
that defines a set of method signatures, but not their implementation.

We user the QPU model as a \textit{template} for defining \textit{QPU classes} with specific functionalities.
For example ``cache'', ``join'', and ``index partition manager'' classes provide different query processing functionalities,
but all conform to the properties of the QPU Mode.
QPU classes can be viewed as classes that implement the QPU abstract class.

Finally, \textit{QPU instances} can be viewed as specific instances of a QPU class,
with a specific configuration.
For example, different instances of the ``secondary index'' class can be used to
implement the partitions of a partitioned index,
or indexes on different attributes.
As another example, a specific materialized view is implemented by an instance of the
``materialized view'' class,
with the view's definition as a configuration parameter.

In the rest of this thesis, we use the terms query processing unit, QPU, and unit interchangeably to refer to QPU instances.

The query processing unit component model defines a \textit{system component} with the following properties.

\begin{figure}[H]
  \centering
    \includegraphics[width=0.5\textwidth]{./figures/design_pattern/qpu_interfaces.pdf}
  \caption{A conceptual depiction of the QPU model interfaces.}
  \label{fig:qpu_interfaces}
\end{figure}

\subsubsection{Query, input stream, and domain interfaces.}
The principal characteristic of the QPU component is that is exposes three interfaces for communicating with other QPU
instances.
Figure~\ref{fig:qpu_interfaces} shows a conceptual depiction of the query processing unit model's interfaces.

\bigskip
\noindent
\textbf{Query interface.}
Query processing units expose an interface for receiving query requests.
This interface is common among all QPU classes so that a QPU can send query requests to other QPUs, regardless of their class.
This is the mechanism with which QPUs interoperate to perform query processing tasks,
and forms the basis of the query processing system's computation model (\S\ref{sec:computation_model}).

Each QPU instance specializes in a subset of the queries that can be expressed by the interface's query
language.
This set of queries depends on its class, its configuration (\S\ref{sec:qpu_config}), and the topology of the parts of the QPU graph is is connected to.
For example, a QPU may only serve queries about a specific database table,
while a Join class QPU will specifically serve join queries using partial results.
The set of queries that a QPU instance can process is the query interface's \textit{domain}.

The QPU's query interface has \textit{streaming semantics}.
An invocation of the query interface initiates a stream between the QPU that sent the query request and the one that
received it;
query results are returned through that stream; each stream record is a result of the query.
This allows the QPU model to bridge one-off and long-running queries.
We present the query interface in more detail in Section~\ref{ref:query_interface}.

\bigskip
\noindent
\textbf{Input stream interface.}
Issuing a query request initiates a stream of query results.
The input stream interface is the interface through which the query processing unit receives this input stream.
This interface is not open:
a QPU cannot receive an input stream not associated with a query that it has issued.

\bigskip
\noindent
\textbf{Domain interface.}
As presented above, each QPU instance specializes in a specific set of queries,
which is called it's query interface domain.
In order for QPUs to collaborate during query processing by issuing queries to one another,
a unit must have information about the domains of its downstream connections.
The domain interface allows domain information to be disseminated through the QPU graph:
a unit can use the domain interface of one of its downstream connections to retrieve its domain.
We present the domain interface in more detail in Section~\ref{sec:domain_dissemination}.

\subsubsection{Configuration}
\label{sec:qpu_config}

Upon initialization, each QPU is given a set of configuration parameters.
Configuration parameters can be categorized in:
\begin{itemize}
  \item Class-specific configuration, which includes parameters such as cache size or the definition of a materialized view.

  \item Topology configuration, which consists of endpoints of a QPU's downstream connections in the QPU graph.
\end{itemize}

\subsubsection{Local graph view}
A QPU maintains information about the query interface domain of each of its downstream connections.
It uses this information to:
(1) validate if it can process a given query, and
(2) generate downstream sub-queries in order to retrieve partial results required for processing a given query.
The QPU implements its local graph view as a data structure, called the domain tree (\S\ref{sec:qpc_tree}).

\subsubsection{Query Processing State.}
Each QPU maintains \textit{internal} state, that is accessible only by that QPU.

We distinguish the QPU state in three parts according to its functionality.
Moreover, QPUs that have downstream connections maintain information about these connections, which is
used for generating downstream query requests.
We call this part of the state \textit{local graph view}.
Finally, query processing units that implement derived state structures and QPUs that store intermediate query processing
results, for example in streaming join computations, maintain \textit{query processing state}.

\subsubsection{Initialization, query processing, and input stream processor methods.}
The functionality of a query processing unit can be modeled using three methods:
\begin{itemize}
  \item The \textit{initialization method} (section~\ref{sec:initialization_func}), which is executed when the QPU is
  initialized.

  \item The \textit{query processing method} (section~\ref{sec:query_processing_func}), which is executed for each
  query request received by the QPU, and is responsible for processing the query and sending results to the response stream.

  \item The \textit{input stream processor method} (stream processor method for short) (section~\ref{sec:callback_func}), which is executed for each record
  received through an input stream.

\end{itemize}

The QPU model defines the signatures of these methods, and each QPU class provides implementations for them.
The functionality of a QPU class is defined by the implementations that the class provides for the three QPU methods.

\begin{figure}[H]
  \centering
    \includegraphics[width=0.5\textwidth]{./figures/design_pattern/qpu_abstraction.pdf}
  \caption{QPU composition.}
  \label{fig:qpu_abstraction}
\end{figure}

Figure~\ref{fig:qpu_abstraction} shows a conceptual depiction of how the QPU model enables composition.
When the QPU's query API is called, an output stream ($R_A$) is established between the unit and the sender,
and the unit's query processing method is invoked for the given query.
The query processing method can read the QPU's state, and can perform downstream queries to other units.
For each downstream query, a corresponding stream is established ($Q_{A.1}$ and $Q_{A.2}$).
When a record is received from one of the streams, the QPU's stream processor method is invoked.
Each invocation of the stream processor method processes a received record, and returns the result to the query processing
method.
Upon receiving a result from a stream processor method,
the query processing method can potentially write to the QPU's state and/or emit a record to the output stream.


\subsection{Query Processing Unit component model specification}
\label{ref:specification}

In this section we present the detailed specification of the query processing unit component model.

\subsubsection{Query interface}
\label{ref:query_interface}
% we first present a high level overview of the QPU model's interface, and then describe each of its elements in more detail.

Query processing units expose an interface for receiving query requests:

\begin{displaymath}
  Query(QueryRequest) \rightarrow QueryResponse
\end{displaymath}

\begin{itemize}
  \item $QueryRequest$ specifies a projection, a predicate on the data items' \textit{attributes},
  and a \textit{timestamp} or \textit{time interval}.

  \item $QueryResponse$ is a stream containing the query's results.
\end{itemize}

\bigskip
\noindent
\textbf{Query response}.

\noindent
$QueryResponse$ is a stream with the following structure:
\[
  QueryResponse = [StreamRecord]
\]
where
\[
  StreamRecord =
\]
\[
  (DataItemID,~[(AttributeName,~AttributeValue_{old},~AttributeValue_{new})],~Timestamp)
\]


\bigskip
\noindent
\textbf{Query types.}

\noindent
We categorize queries in three types: snapshot, interval or hybrid queries.
A snapshot query is an one-time query that is evaluated on a snapshot of the corpus data,
and returns the data items that items that match the query predicate.

An interval query is a \textit{persistent} query.
It is akin to subscribing to the given query predicate;
Each time an update to the corpus causes a result to be added or removed from the query's results,
the query notifies the subscriber.

Finally, a hybrid query is a combination of the two other types.
It is used in order to avoid missing updates in the common case in which a snapshot query is
directly followed by an interval query.

\medskip
\noindent
\textbf{Snapshot queries.}
Given a query $Q$,
specifying a projection $Proj_Q$, a predicate $Pred_Q$, and a timestamp $t_Q$,
a snapshot query is evaluated on a snapshot of the corpus that contains the effects of all updates with
$timestamp$ $<$ $t$.
For each data item $d$ that satisfies $Pred$, $QueryResponse$ contains a $StreamRecord$ of the form:
\[
(DataItemID,~[(AttributeName,~null,~AttributeValue_{new})],~Timestamp)
\]
The attributes contained in $StreamRecord$ are specified by $Proj_Q$.

This represents the state of the data item $DataItemID$ at timestamp $Timestamp$.
Each element of $[(AttributeName$, $AttributeValue_{old}$, $AttributeValue_{new})]$ indicates that
the data item is associated with an attribute $AttributeName$ with the value $AttributeValue_{new}$
% \end{sloppypar}

\medskip
\noindent
\textbf{Interval queries.}
Given a query $Q$,
specifying a projection $Proj_Q$, a predicate $Pred_Q$, and an interval $[t_1, t_2)$,
a $StreamRecord$ is added to $QueryResponse$ each time one of the following is true:
\begin{itemize}
\item An update creates a data item $d$, and $d$ satisfies $Q$

\item An update deletes a data item $d$ satisfied $Q$ before deletion.

\item An update modifies an existing data item $d$,
causing to either start satisfying $Q$, stop satisfying $Q$,
or continue satisfying $Q$ but with some of the attributes in $Proj_Q$ having been modified.
\end{itemize}

\noindent
This specification represents the following cases:
\begin{itemize}

\item An update modifies a data item so that its state before the update is applied does not satisfy $Pred$,
but its state after the update is applied satisfies $Pred$.
In that case, the data item needs to be added to the posting list of an index entry, or to the results of a
materialized view.

\item An update modifies a data item so that its state before the update is applied satisfies $Pred$,
but its state after the update is applied does not satisfy $Pred$.
In that case, the data item needs to be removed from the posting list of an index entry, or to the results of a
materialized view.

\item An update modifies a data item, both its state before the update is applied and after satisfies $Pred$,
and the data item's state stored as part of the index entry of the materialized view (because of $Proj$) is modified.

\end{itemize}

In this case of interval queries, $StreamRecord$ has the form:
\[
(DataItemID,~[(AttributeName,~AttributeValue_{old},~AttributeValue_{new})],~Timestamp)
\]
This represents an update to the the data item $DataItemID$, with timestamp $Timestamp$;
Each elements of $[(AttributeName$, $AttributeValue_{old}$, $AttributeValue_{new})]$ indicates that
the update modified the value of attribute $AttributeName$ from $AttributeValue_{old}$ to $AttributeValue_{new}$.
% \end{sloppypar}

\medskip
\noindent
\textbf{Hybrid queries.}
Given a query $Q$,
specifying a projection $Proj_Q$, a predicate $Pred_Q$, and an interval $[t_1, t_2)$,
a hybrid query is equivalent to executing two queries in parallel:
A snapshot query with timestamp $t_1$, and an interval query with interval $[t_1, t_2)$.
In this $QueryResponse$ contains a mix of both types of $StreamRecord$.

% \noident
% Given a $QueryRequest$ that specifies a projection $Proj$,
% an attribute predicate $Pred$
% and a time interval $T$ $=$ $[t_1, t_2)$:
% \begin{itemize}

%   \item if \textbf{$t_1$ $<$ $t_2$},
%   then $QueryResponse$ contains an update event for each update $u$ with $t_1$ $\leq$ $timestamp$ $<$ $t_2$,
%   for which one of the following is true:
  
%   \end{itemize}
%   We term this type of query \textit{an interval query}.

%   By using a upper bound ($t_2$) in the future (a timestamp that the system has not yet reached),
%   an interval query can continue receiving future updates that satisfy $Pred$.
%   This provides a mechanism for \textit{subscribing to notification for updates}.


  % then the query is performed on a \textit{snapshot} of the corpus that contains the effects of all updates with
  % $timestamp$ $<$ $t$.
  
  % We term this type of query a \textit{snapshot query}.


% \noindent
% A $StreamRecord$ can be of the two following types of information:
% \begin{itemize}
%   \begin{sloppypar}
%   \item The \textbf{state of a data item}.

%   \begin{sloppypar}
%   \item An \textbf{update event} for a modification of a data item (a creation, modification, or deletion
%   of a data item).
%   In this case, $StreamRecord$ has the form:
%   \[
%   (DataItemID,~[(AttributeName,~AttributeValue_{old},~AttributeValue_{new})],~Timestamp)
%   \]
%   This represents an update to the the data item $DataItemID$, with timestamp $Timestamp$;
%   Each elements of $[(AttributeName$, $AttributeValue_{old}$, $AttributeValue_{new})]$ indicates that
%   the update modified the value of attribute $AttributeName$ from $AttributeValue_{old}$ to $AttributeValue_{new}$.
%   \end{sloppypar}
% \end{itemize}




% \end{itemize}

% By returning the latest update before a given timestamp $t$,
% a snapshot query effectively returns the \textit{state} of each data item that satisfies $Pred$ at $t$.
% Therefore,
% A snapshot query refers to a \textit{snapshot} of the corpus that contains the effects of all update with $timestamp$ $<$ $t$.

% An interval query returns may returns any update with timestamp within the specified time interval which modifies a
% data item so that either its old state value before applying the update or the new value after  is starts or it stops
% satisfying $Pred$.

\bigskip
\noindent
\textbf{Response stream mode.}

\noindent
The query response stream can be either synchronous or asynchronous.
In a synchronous stream, the sender blocks until the stream records has been received and processed by the receiver.

\bigskip
\noindent
\textbf{Query Language.}

\noindent
% https://documentation.basis.com/BASISHelp/WebHelp/usr2/sql_grammar.htm
% http://www.h2database.com/html/grammar.html#expressionz
The interface supports a query language with an SQL-like syntax.
The query language supports point and range queries, logical operators, aggregation functions, and joins.
We argue that these is no inherent limitation in the QPU model that prevents it from supporting a more complex
query language (for example supporting nested queries).
However, we consider additional functionalities to be out of the scope of this work.
We believe this query language can effectively demonstrate that the QPU model can be used as building
block for constructing fully-functional query processing systems.

The QPU model's query language has following syntax:

\begin{lstlisting}[
  caption={Query language of the QPU's query interface},
  label={lst:query_language},
]
QueryRequest          ::=  SELECT SelectExpression
                           FROM TableExpression
                           WHERE PredicateExpression
                           INTERVAL IntervalExpression
                           [ GROUP BY attributeName ]
                           [ ORDER BY OrderByExpression { ASC | DESC } ]
                           { SYNC | ASYNC }

SelectExpression      ::=  ALL |
                           SelectExprItem , SelectExpression |
                           SelectExprItem

SelectExprItem        ::=  SUM(attributeName) |
                           AVG(attributeName) |
                           MAX(attributeName) |
                           MIN(attributeName) |
                           attributeName

TableExpression       ::=  tableName JOIN tableName On
                           tableName.attributeName = tableName.attributeName |
                           tableName

PredicateExpression  ::=  PredicateExpression OR
                              PredicateExpression |
                           PredicateExpression AND PredicateExpression |
                           NOT PredicateExpression |
                           Term Op Term

Term                  ::=  attributeName | Value

Op                    ::=  > | >= | < | <= | = | !=

Value                 ::=  stringValue | floatValue | intValue |
                           dateTimeValue | timestampValue

IntervalExpression    ::=  FROM TimestampTerm [ TO TimestampTerm ]

TimestampTerm         ::=  SYSTEM START | LATEST | timestampValue

\end{lstlisting}

The \texttt{INTERVAL} syntax is used to specify the query type.
Queries without a \texttt{TO} part are snapshot queries;
queries with a \texttt{TO} are interval or hybrid queries.
Queries with \texttt{LATEST} keyword in the \texttt{FROM} part are interval queries,
while queries with with a specific timestamp (or the \texttt{SYSTEM START} keyword) are
hybrid queries.
The \texttt{SYSTEM START} keyword is used to indicate the earliest available timestamp.

The \texttt{SYNC} or \texttt{ASYNC} is used to specify the response stream mode.

In practice, each QPU instance specialized in a subset of the queries that can be expressed by this query language,
according to the functionality supported by its class.
For example, a QPU class that implements a join operator can perform a join over two input streams,
but cannot evaluate a $PredicateExpression$, or perform an $SUM$ on an attribute of the join result.
This can be achieved by connecting ``join'', ``filter'', and ``aggregator'' QPUs.
We present in detail these QPU classes in section~\ref{sec:qpu_classes},
and how they are composed to provide complex query processing functionalities in section~\ref{sec:query_processing_system}.

Moreover, instances of a certain class may support different parts of the query language according to their
configuration.
For example, two instances of a filter operator QPU class may support predicate queries for different tables.

\subsubsection{Query processing state}

Query processing units that encapsulate derived state structures such as indexes, materialized views and
caches, store these data structures in the part of their state that we call \textit{query processing state}.
Additionally, streaming operator QPUs such as joins use this part of the state to store intermediate state.

We model the query processing state as set of key-value pairs, ordered by key:
\[
  (Key,~[State],)
\]
where
\[
  State = (DataItemID,~[(AttributeName,~AttributeValue)],~Timestamp)
\]
% and
% \[
%   Timestamp_S := \{t \in [DataItemState] : t > Timestamp_U~\forall~Timestamp_U \in [DataItemState] \}
% \]

% The timestamp $Timestamp_S$ of an entry of the query processing state is the latest of the timestamps $Timestamp_U$
% contained in the entry's value.

Listing~\ref{lst:qpu_query_proc_state} defines the QPU's query processing states using pseudocode:

\begin{lstlisting}[
  language=pseudo,
  caption={Pseudocode for the QPU's query processing state},
  label={lst:qpu_query_proc_state}
]
type AttributeName string

type AttributeValue union {
  string
  float
  int
  dateTime
  timestamp
}

type State {
  dataItemID  string
  attributes  [(AttributeName, AttributeValue)]
  ts          timestamp
}

class QueryProcessingState
  function Get(Key_low, Key_high, Timestamp_low, Timestamp_high) [(Key, [State])]
  function Put(Key, State)
\end{lstlisting}

\begin{itemize}
  \item $Put$ modifies the value of the query processing state's entry for the given key.
  It can be used with a non-existing key to create a new entry.

  \item $Get$ retrieves the query processing state entries with $Key_{low}$ $<$ $key$ $\leq$ $Key_{high}$.
  For each entry, the updates with $Timestamp_{low}$ $<$ $Timestamp$ $\leq$ $Timestamp_{high}$ retrieved.
\end{itemize}

Essentially, the QPU's query processing state is versioned.
In that way, QPU's can process queries about any timestamp that they have received updates for.


\subsubsection{Initialization method}
\label{sec:initialization_func}

Each QPU invokes an initialization method when it starts its execution.

\begin{lstlisting}[
  language=pseudo,
  caption={Initialization method signature},
  label={lst:init_func}
  ]
type DownstreamConnection {
  endpoint string
  domain DomainTree
}

function Init(QPState, [DownstreamConn])
\end{lstlisting}

\noindent
Listing~\ref{lst:init_func} shows the initialization method's signature.
$ProcessQuery$ receives as arguments:
\begin{itemize}
  \item $QPState$, which is a handler that enables $Init$ to read from and write to QPU's query processing state.

  \item A list of $DownstreamConn$, each consisting of the endpoint of a downstream connection and a data structure
  representing the connection's query interface domain (section~\ref{sec:qpc_tree}).
  $Init$ can therefore send downstream query requests.
\end{itemize}


\subsubsection{Query processing method}
\label{sec:query_processing_func}

The query processing method is responsible for processing a single query.
It spawns a result stream and sends the results back to the requestor over that stream.

For each query $q$ being processed, the QPU initiates an output stream, $R_q$,
and executes an instance of the query processing function, $QPF_q$.
$QPF_q$ is responsible for emitting records to $R_q$.
Moreover, if $QPF_q$ initiates input streams $I_{q-1}$, $I_{q-2}$, ..., then $QPF_q$ is responsible for handing the return
values of stream processor methods for records received through $I_{q-i}$.

\begin{lstlisting}[
  language=pseudo,
  caption={Query processing method signature},
  label={lst:query_processing_func},
]
function ProcessQuery(QueryRequest, QPState, [DownstreamConn], ResponseStream)
\end{lstlisting}

\noindent
Listing~\ref{lst:query_processing_func} shows the query processing method's signature.
In addition to $QPState$ and $[DownstreamConn]$, $ProcessQuery$ receives:

\begin{itemize}
  \item $QueryRequest$, which represents the received query request.

  \item $ResponseStream$, a handler it can use to emit result to the output stream.

\end{itemize}

An instance of the query processing method is executed for each received query request,
therefore query processing unit can run multiple instances of the query processing method in parallel.

\subsubsection{Input stream processor method}
\label{sec:callback_func}

The input stream processor method is responsible for processing a record received through an input stream.
It can read from and write to the query processing unit state,
and a (potentially empty) list of $StreamRecord$ to the query processing method.

\begin{lstlisting}[
  language=pseudo,
  caption={Stream processor method signature},
  label={lst:callback_func}
]
function ProcessInputRecord(StreamRecord, QueryRequest, QPState)
          returns [StreamRecord]
\end{lstlisting}

\noindent
Listing~\ref{lst:callback_func} shows the query processing method's signature.

An instance of the stream processor method is executed for each record received through an input stream.

\subsection{Stream semantics}

In this section we describe more detail the semantics of the stream connections between query processing units.

\medskip
\noindent
Apart from \textit{data records} (updates), \textit{control records} can also be sent through a stream.
Although ata records can be sent only in one direction (``upstream''), control records can be sent in both directions.
Types of control records include acknowledgements, heartbeats, and re-send requests.
A re-send records requests for a data record to be re-send.

\medskip
\noindent
Sending a data record can be either \textit{synchronous} or \textit{asynchronous}.
A synchronous send operation blocks until an acknowledgement for the data record is received.

\medskip
\noindent
Finally, we assume that stream connections do not drop, re-order, of duplicate messages;
however messages may be arbitrarily delayed.
These guarantees are not based on assumptions about the transport layer, but as we discuss in In chapter~\ref{ch:evaluation}
are implemented by query processing units on top of potentially unreliable connections.

\subsection{QPU classes}
\label{sec:qpu_classes}

As described in the previous section, the query processing unit component model has the role of ``template'',
defining unified semantics that every QPU conforms with.
This ensures that QPU instance with different functionalities (classes) and configurations can be interconnected and
can interoperate to perform query processing tasks.

A QPU class is an \textit{instantiation} of the query processing unit model:
it defines the implementations of the \textbf{initialization}, \textbf{query processing} and \textbf{stream processor}
methods.

In this section, we present a categorization of QPU classes according to their general characteristics,
and demonstrate some examples of QPU classes.
We present additional QPU classes in chapters~\ref{ch:case_studies}, \ref{ch:proteus}, \ref{ch:evaluation}.

We categorize QPU classes in three groups, according to their general characteristics:
\begin{itemize}
  \item \textbf{Relational operator classes}.
  Classes in this group encapsulate \textit{streaming relational operators}.
  A relational operator QPU receives one or more input data streams, and perform a transformation over these streams.
  For every record received through one of the input streams, the QPU emits zero or one record at the output stream.

  Every input stream of relational operator QPU is the output stream of another QPU, and has been establish as a response
  to a query request.

  Examples of QPU classes in this group are:
  \begin{itemize}
    \item \textbf{Filter:}
    A filter QPU receives records from an input stream, and  emits at its output those records satisfy a given condition.

    \item \textbf{Join}:
    A join QPU encapsulates a streaming join operator.
    It receives records from two or more input streams, and performs a join operation one those stream, according
    to parameters specified by a given query request.
    The join QPU initiates input streams by sending the appropriate query requests to its downstream connections,
    and emits ths join operation result as its output stream.

    \item \textbf{Aggregator classes}:
    Aggregator QPU classes encapsulate aggregation functions such as count, sum, average, and min or max.
    An aggregator QPU performs a streaming aggregation over an input stream;
    It emits a record at its output stream for each input record that changes the computed aggregation value.
  \end{itemize}

  \item \textbf{Derived state classes}.
  Classes in this group encapsulate derived state structures, such as indexes, caches, and materialized views.

  This group includes the following classes:
  % QPUs of derived state classes make use of the same use of the ``query request - output stream'' semantics to implement their functionality:
  \begin{itemize}
    \item \textbf{Secondary index and Materialized view:}
    A secondary index (or materialized view) QPU receives its index or view definition as a configuration parameter.

    The QPU's initialization method establishes an input steam by sending an \textit{interval} query
    (a query without an upper bound timestamp) to its downstream connection:
    In that way, the QPU effectively \textit{subscribes to notifications} for updates to the corpus.
    For each record received through the input stream, the stream processor method updates the query processing state accordingly.
    When a query request is received,
    the query processing method computes the results by reading from the query processing state,
    and emits them to the output stream.

    % For simplicity we assume that a secondary index QPU maintains an index for a single attribute (and the same for materialized view QPUs respectively).
    \item \textbf{Cache:}
    When receiving a query request, a cache QPU's query processing method first determines if the query result is stored
    in the query processing state.
    If yes, the method retrieves the corresponding query results and emits them at the output stream.
    Alternatively, it sends a query request at the QPU's downstream connection,
    with the given query.
    The stream processor method stores each received record, and then returns it to the query processing method with emits it
    at the output stream.
    \end{itemize}

  \item \textbf{Routing classes}.
  Classes in this group encapsulate query processing functionalities that can be characterized as ``query routing''.
  This includes coordinating access to partitioned or replicated derived indexes and materialized views,
  or load balancing.

  Examples of classes in this group include:
  \begin{itemize}
    \item \textbf{Partition manager:}
    A partition manager QPU is responsible for coordinating access secondary index or materialized view partitions,
    encapsulated by the corresponding QPU classes.

    A partition manager QPU has downstream connections to a set of QPUs representing partitions.
    When a query request is received, the QPU's query processing method determines which partitions need to be contacted,
    generated the corresponding queries and sends them as downstream query requests.
    To enable this, the partition manager QPU maintains information about the partitioning scheme and the portion of
    the partitioned space that corresponds to each of its downstream connections connections at its query processing
    capabilities spaces
    The unit then merges the input streams and emits the result as its output stream.

    \item \textbf{Load balancer and replica manager:}
    QPUs of these classes have similar functionalities with the partition manager class.
    Given a query, the query processing method of a load balancer or replica manager QPU selects the most suitable
    among the QPU's downstream connections according to a certain criterion (defined by QPU's class and configuration),
    forwards the given query to that connection, and then forwards the resulting input stream to the output stream.
    \end{itemize}

  \item \textbf{Corpus driver classes}.
  Classes in this group are responsible for connecting the QPU graph with the corpus.
  QPUs of these classes do not support downstream connections to other QPUs.
  Because of their functionality, corpus driver QPUs are only used as leaves of the QPU graph.
  In fact, as we explain in section~\ref{sec:graph_topology}, every leaf node of the QPU can only be a corpus driver QPU.

  When a query request is received, the query processing method of a corpus driver QPU uses the interface and mechanisms
  of they corpus database in order to generate and emit the output stream that corresponds to the given query.
  This can include reading from the database that stores the corpus, subscribing to update notifications,
  or performing queries.

  The corpus driver classes act as a wrappers for the corpus, exposing a common interface and semantics to the
  QPU graph, independent of how the corpus is stored and accessed.
  As a result, corpus driver classes are database-specific.

  QPU-based query processing systems can be compatible with any corpus database --- or, more generally, source of updates ---
  for which there is a corresponding corpus driver class.
\end{itemize}

\subsubsection{QPU class case studies}
\label{sec:qpu_class_examples}

\textbf{Filter}

Algorithms~\ref{algo:filter_query_processing_func} and~\ref{algo:filter_algorithm_func} show the query processing and
stream processor methods respectively for the filter QPU class using pseudocode.


\begin{algorithm}
\caption{Filter QPU class query processing method}
\label{algo:filter_query_processing_func}
\begin{algorithmic}
\Function{ProcessQuery}{queryReq, qpState, [downstreamConn], outputStream}
\State conn = get endpoint from [downstreamConn] \Comment{we assume one downstream connection}
\State inStream = forward queryReq to conn
\While{not at end of this the stream}
\State inRecord = inStream.Recv()
\State result = ProcessInputRecord(inRecord, queryReq, qpState)
\If{result is not empty}
\State outStream.Send(result)
\EndIf
\EndWhile
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Filter QPU class stream processor method signature}
\label{algo:filter_algorithm_func}
\begin{algorithmic}
\Function{ProcessInputRecord}{inRecord, queryReq, qpState}
\If{inRecord satisfies queryReq}
\State \Return inRecord
\Else
\State \Return []
\EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}


\bigskip
\noindent
\textbf{Secondary index}

Algorithms~\ref{algo:index_init_func}, ~\ref{algo:index_query_processing_func}, and~\ref{algo:index_callback_func}
show the initialization, query processing, and stream processor methods respectively for the secondary index QPU
class using pseudocode.

\begin{algorithm}
\caption{Secondary index QPU class initialization method}
\label{algo:index_init_func}
\begin{algorithmic}
\Function{Init}{qpState, [downstreamConn]}
\State conn = get endpoint from [downstreamConn] \Comment{we assume one downstream connection}
\State queryReq = generate interval query
\State inStream = send queryReq to conn
\While{not at the end of the stream}
\State inRecord = inStream.Recv()
\State ProcessInputRecord(inRecord, null, qpState)
\EndWhile
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Secondary index QPU class query processing method}
\label{algo:index_query_processing_func}
\begin{algorithmic}
\Function{ProcessQuery}{null, qpState, [downstreamConn], outputStream}
\State conn = GetEndpoint([downstreamConn]) \Comment{we assume one downstream connection}
\State inStream = forward queryReq to conn
\While{not at end of this the stream}
\State inRecord = inStream.Recv()
\State result = ProcessInputRecord(update)
\If{result is not empty}
\State outStream.Send(result)
\EndIf
\EndWhile
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Secondary index QPU class stream processor method}
\label{algo:index_callback_func}
\begin{algorithmic}
\Function{ProcessInputRecord}{inRecord, queryReq, qpState}
\State (dataItemID, [attributeDelta], timestamp) = parse inRecord
\For {(attrName, attrValOld, attrValNew) in [AttributeDelta]}
\If{attrValOld is not null}
\State indexTerm = build index term from attrName and attrValOld
\State postingList = qpState.Get(indexTerm, indexTerm)
\State postingList' = remove dataItemID from postingList
\State pState.Put(indexTerm, postingList')
\EndIf
\If{attrValNew is not null}
\State indexTerm = build index term from attrName and attrValNew
\State postingList = qpState.Get(indexTerm, indexTerm)
\State postingList' = add dataItemID from postingList
\State pState.Put(indexTerm, postingList')
\EndIf
\EndFor
\EndFunction
\end{algorithmic}
\end{algorithm}


\section{QPU-based query processing systems}
\label{sec:query_processing_system}

\subsection{Query processing system architecture}

\begin{figure}[t]
  \centering
    \includegraphics[width=0.4\textwidth]{./figures/design_pattern/qpu_graph_emergent_properties.pdf}
  \caption{QPU graph example}
  \label{fig:qpu_graph_emergent_properties}
\end{figure}

A \textit{QPU-based} query processing system is a directed acyclic graph (DAG) with query processing unit instances as
graph nodes.
Edges represent potential query request - response stream relations between QPUs:
a directed edge from $QPU_a$ to $QPU_b$ indicates that $QPU_a$ is able to send query requests to $QPU_b$.
A query request sent from $QPU_a$ to $QPU_b$ initiates a stream connection between $QPU_a$ and $QPU_b$;
$QPU_b$ emits query results through that stream.

The corpus is represented by the graph's leaf nodes (nodes with no outgoing connections).
Queries enter the QPU graph through root nodes (nodes with no incoming connections).

The capabilities of a QPU-based query processing system are emergent from the functionalities of the QPUs it is composed of,
as well as the graph topology.
For example, consider the QPU graph depicted in Figure~\ref{fig:qpu_graph_emergent_properties}, where:

\begin{lstlisting}[caption={Customer and Orders tables attributes}]
TABLE Customers(CustomerID, Email, Address)
TABLE Orders(OrderID, CustomerID, OrderStatus, OrderDate)
\end{lstlisting}

\begin{itemize}
  \item $DB$ $driver_1$ can process queries with the form:
  \begin{lstlisting}
  SELECT SelectExpression from Customers INTERVAL IntervalExpression
  \end{lstlisting}
  where $SelectExpression$ can contains one or more attributes of the $Customers$ table.

\item $DB$ $driver_2$ can process queries with the form:
\begin{lstlisting}
SELECT SelectExpression FROM Orders INTERVAL IntervalExpression
\end{lstlisting}
where $SelectExpression$ contains one or more attributes of the $Orders$ table.

\item $Filter_1$ can send downstream queries to $DB$ $driver_1$ and filter the resulting input stream based on a given
attribute predicate.
Therefore, $Filter_1$ can process queries of the form:
\begin{lstlisting}
SELECT SelectExpression FROM Customers
WHERE PredicateExpression
INTERVAL IntervalExpression
\end{lstlisting}
where $SelectExpression$ and $PredicateExpression$ contain attributes of the $Customers$ table.

\item Similarly, $Filter_2$ supports queries of the form:
\begin{lstlisting}
SELECT SelectExpression FROM Orders
WHERE PredicateExpression
INTERVAL IntervalExpression
\end{lstlisting}
where $SelectExpression$ and $PredicateExpression$ contain attributes of the $Orders$ table.

\item $Join$ can send downstream queries to $Filter_1$ and $Filter_2$,
and join the two input streams based on a given attribute.
Since the only attribute the two table in the example can be joined on is $CustomerID$,
$Join$ can process queries of the form:
\begin{lstlisting}
SELECT SelectExpression
FROM Customers JOIN Orders ON Customers.CustomerID = KnowledgeBase.CustomerID
WHERE PredicateExpression
INTERVAL IntervalExpression
\end{lstlisting}
where $SelectExpression$ and $PredicateExpression$ contain attributes of both tables.

\end{itemize}

In section~\ref{sec:computation_model} we describe how a query such as the aforementioned is processed by a QPU-based
query processing system.
Moreover, in section~\ref{sec:qpc_tree} we describe how the set of queries a query processing unit can process are
represented and used by other QPUs.

\subsubsection{QPU-graph topology rules}
\label{sec:graph_topology}
Although the QPU model than guarantees that a query processing unit can communicate with any other QPU,
a QPU DAG cannot have any arbitrary topology.
This is because the functionality of facilitating of each QPU class entails some requirements about:
(1) number of the QPU's downstream connections, and (2) the query interface domain of these downstream connection.
From these \textit{class-specific topology requirements}, certain higher-level graph topology rules emerge:
\begin{itemize}
  \item Any QPU graph mush have corpus driver QPUs as its leaf nodes.
  Corpus drivers generate the initial streams that all other QPUs build on.

  \item Most QPUs in the relational operator and derived state groups must have a single downstream connection.
  Exception are relational operator QPUs that by definition operate on more that one input streams, such as join QPUs.

  \item A materialized view QPU must have a downstream connection that:
  \begin{itemize}
    \item Can process the query the is the materialized view's definition.
    \item Supports \textit{interval queries} on that query.
  \end{itemize}
  This is because, the materialized view QPU needs to receive an input stream of updates that correspond to changes in
  the result of that query, in order to incrementally update the materialized view.

  \item Similarly, a secondary index QPU must have a downstream connection that can provide a stream of updates on the
  attribute that QPU is configured to index.

  \item A cache QPU must have a single downstream connection, which can be any other QPU.

  \item Similarly, a filter QPU can have a downstream connection to any QPU.

  \item A partition manager QPU can have one or more downstream connections;
  The connections must be to derived state QPUs that implement partitions of a derived state structure.
  In more detail:
  \begin{itemize}
    \item All downstream connection of must be of the same QPU class.

    \item They must be configured as partitions of a common logical derived structure, based on the same partitioning
    scheme and partitioning key.
  \end{itemize}

  \item A load balancer QPU can have one or more downstream connections;
  The QPU is responsible for performing load balancing on the queries that belong in the \textit{intersection} of the
  query interface domains of its downstream connection.
  Because of that, the intersection of the query interface domains of the downstream connection of the load balancer
  QPU must be non empty.
\end{itemize}

The above list is inherently non-exhaustive:
any QPU class that can be defined using the QPU model may have additional requirements.

\subsection{Query execution}
\label{sec:computation_model}

The query execution computations of QPU-based query processing systems are \textit{fully decentralized}.
The distributed computations directly emerge from the initialization, query processing and stream processor methods of the QPUs
the query processing system consists of.
In order to describe the characteristics of query execution in QPU graphs, we first describe the execution of the query
\begin{lstlisting}
Q = SELECT OrderID, OrderStatus, Email
FROM Customers JOIN Orders ON Customers.CustomerID = Orders.CustomerID
WHERE OrderStatus != "shipped" AND OrderDate < 2020-09-14
INTERVAL FROM LATEST TO LATEST
\end{lstlisting}

by the QPU graph of Figure~\ref{fig:qpu_graph_emergent_properties}.

When a $Join$ receives a query request for $Q$, its query processing method generates two downstream queries:
\begin{lstlisting}
Q1 = SELECT CustomerID, Email
FROM Customers
INTERVAL FROM LATEST TO LATEST
\end{lstlisting}

\begin{lstlisting}
Q2 = SELECT CustomerID, OrderStatus
FROM Orders
WHERE OrderStatus != "shipped" AND OrderDate < 2020-09-14
INTERVAL FROM LATEST TO LATEST
\end{lstlisting}

$Join$ sends a query request for $Q1$ to $Filter_1$, and a query request for $Q2$ to $Filter_2$.

When a $Filter_1$ receives $Q1$, its query processing method generates the query and sends it as downstream query request
to $Corpus$ $driver_1$:

\begin{lstlisting}
Q3 = SELECT CustomerID, Email
FROM Customers
INTERVAL FROM LATEST TO LATEST
\end{lstlisting}

Similarly, $Filter_2$ generates and sends to $Corpus$ $driver_2$ the following query:

\begin{lstlisting}
Q4 = SELECT CustomerID, OrderStatus
FROM Orders
INTERVAL FROM LATEST TO LATEST
\end{lstlisting}

$Corpus$ $driver_1$ reads from $Customers$ and generates an output stream that for each data item $d$ $\in$ $Customers$
contains the most recent update. Similarly, $Corpus$ $driver_2$ generates an output stream for $Orders$.
$Filter_2$ emits at its output stream only the input stream updates for which
\begin{lstlisting}
OrderStatus != "shipped" AND OrderDate < 2020-09-14
\end{lstlisting}
is true.
Because $Q1$'s $PredicateExpression$ is empty, $Filter_1$'s output stream is identical to its input stream.
Finally, $Join$ receives the results of $Q1$ and $Q2$ as input streams; its query processing method join updates from
the two streams where

\begin{lstlisting}
Customers.CustomerID = Orders.CustomerID
\end{lstlisting}
and emits the results at its output stream.

More generally, given a query $q$, the query processing method of a QPU $Q_0$ may either process $q$ by reading from its
query processing state --- for example in the case of a materialized view QPU --- or generate and send query requests to
some of its downstream connections, $Q_1$, $Q_2$ .., in order to initialize input streams required for processing the query.
In both cases, the QPU computed the results of $q$ and emits them at the output stream that corresponds to $q$.

The same process is performed at each of the downstream connections of $Q_0$, and their downstream connection respectively,
propagating through the QPU graph from its root to its leaves.
This creates a \textit{query execution sub-graph} composed of the QPUs that participate in the processing of $q$.
When a QPU can process a received query request without sending downstream query requests, it becomes a leaf node of
the query execution sub-graph of $q$.
QPU classes that become query execution sub-graph leaf nodes are corpus driver QPUs, and derived state QPUs.
Leaf nodes produce output streams that are then received as input stream at their ``parent'' nodes.
Progressively, each non-leaf QPU in the query execution sub-graph receives an input stream for each query request sent,
and produces itself an output stream.
The output stream of $Q_0$ contains the results of the initial query, $q$.
We call this type computation in a QPU DAG, \textit{query execution mode}.

QPU-based query query processing systems execute a similar type of computations for incrementally updating
secondary indexes and materialized views.
We call this type computation in a QPU DAG, \textit{state maintenance mode}.
There are the following differences between query execution and state maintenance mode:
\begin{itemize}
  \item Query execution is performed in response to a client query (by the query processing method of the QPU that receives the query)
  while state maintenance is performed in response to the initialization of a secondary index of materialized view QPU
  (by the initialization method of the corresponding QPU).
  \item The goal of query execution is to process a client query,
  while the goal state maintenance is to establish a long running stream of notification for corpus updates that
  will be used to incrementally update a derived state data structure.
  \item The root of a query execution sub-graph is one of the QPU DAG's root nodes,
  while the root of a state maintenance sub-graph is a derived state QPU that might be a root or an internal node of the
  graph.
\end{itemize}

State maintenance can be configured to be performed either synchronously or asynchronously, depending on the type of send
operation used for sending update records.
Synchronous state maintenance is achieved by configuring all QPUs.

Based on the above description, the computations run by a QPU-based processing system can be characterized as
\textit{bi-directional dataflow}.
For a given query or state maintenance execution,
query requests flow downwards through the QPU graph, defining an execution sub-graph.
Response streams flow upwards through that sub-graph, each stream corresponding to an edge defined by a query request.

Finally, as described in section~\ref{ref:specification}, a QPU can process multiple queries in parallel,
executing an instance of its query processing method and having an output stream for each query request being processed.
Therefore, multiple different query execution and state maintenance sub-graph can co-exist in parallel in the same QPU DAG.

\subsection{Query execution data structures}

So far in this chapter we have presented a high level description for certain parts of the query processing unit's
functionality.
In this section we present this parts in details.
More specifically, we present the data structure that encodes the QPUs' query interface domain,
and describe how this structure is used by the query processing method to generate downstream queries for a given query.

\subsubsection{Query parse tree}
\label{sec:query_parse_tree}

The first step of a QPU's query processing method is to parse the given query from a string to a form that can be used
for query processing computations.
This form is a \textit{parse tree}.

A parse tree is constructed by applying the QPU query language's syntax rules to a given query string.
More specifically, a parse tree is composed to two types of nodes:

\begin{itemize}
  \item \textbf{Atoms}, which include keywords of the query language ($SELECT$, $FROM$ etc.),
  identifiers (such as table and attribute names), constants, operators and tokens.
  Atoms are leaf nodes of the parse tree.

  \item \textbf{Syntactic categories}, which are constructs built from atoms or other syntactic categories
  following the query language's syntax rules.
  Syntactic categories are internal nodes of the parse tree.
\end{itemize}

\begin{figure}[H]
  \centering
    \includegraphics[width=\textwidth]{./figures/design_pattern/parse_tree.pdf}
  \caption{Query parse tree for the query in Listing~\ref{lst:qpt_example_query}.}
  \label{fig:parse_tree}
\end{figure}

For example, the parse tree for the following query is depicted in Figure~\ref{fig:parse_tree}:
\begin{lstlisting}[
  caption={Query used to demonstrate the query parse tree data structure.},
  label={lst:qpt_example_query},
]
SELECT OrderID, OrderStatus, Email
FROM Customers JOIN Orders ON Customers.CustomerID = Orders.CustomerID
WHERE OrderStatus != "shipped" AND OrderDate < 2020-09-14
INTERVAL FROM LATEST TO LATEST
\end{lstlisting}

\subsubsection{Domain tree}
\label{sec:qpc_tree}

In this section, we present the domain tree data structure.
The domain tree represents a query processing unit's query interface domain,
i.e. the set of queries it can process.
Because each query can be represented as a query parse tree,
a domain tree is constructed by merging the query parse trees of the queries that in the QPU's query interface domain.
Each QPU maintains a domain tree for each of its downstream connections.
The QPU's local graph view consists of this collection of domains trees.
Moreover, each unit constructs its own domain tree based on the domains trees of its connections,
and its functionality.
% The goal of the domain tree is to represent the parse tree of all queries that a QPU can process.
The domain tree is an extension of the query parse tree, which we presented in the previous section.
It uses an additional type of tree node, called \textbf{conjunction}.
A conjunction node represents the \textit{different potential sub-trees} that a syntactic category node
can be evaluated to.
Essentially, a conjunction node expresses the different branches of a syntax rule.

Query processing units use a straightforward algorithm based on transformation and merge rules construct their domain trees.
This algorithm is specific to each QPU class:
\begin{itemize}
  \item A Corpus driver unit constructs its domain tree based on the schema of the corpus table it is responsible for.
  More specifically,
  it 1) uses the table's name as TableExpression node,
  2) creates a SelectExpression subtree according to the table's attributes,
  and 3) constructs the IntervalExpression sub-tree according to its configuration.

  \item A Filter QPU constructs its domain tree by extending the PredicateExpression node of the domain tree of its
  downstream connection, according to the attributes in the SelectExpression node
  (Figures~\ref{fig:qpt_filter_customers} and~\ref{fig:qpt_filter_orders})

  \item A Join QPU merges the two domain trees of its connections as follows.
  It creates a new TableExpression subtree, using the TableExpressions node of the input domain trees, and the
  join syntax rule (Listing~\ref{lst:query_language}),
  and merges the PredicateExpression subtrees of the the input domain trees using a straightforward tree merge algorithm
  (Figure~\ref{fig:qpt_join}).

  \item A Partition Manager unit constructs its domain tree by combining the trees of the PredicateExpression subtrees
  of its connections.
  For example, consider the case of a partition manager QPU connected to two index QPUs.
  The first index QPU is responsible for index entries in the interval $[V_A$, $V_B)$,
  and the second for $[V_B$, $V_C)$.
  The Partition Manager's domain tree will represent the interval $[V_A$, $V_C)$.
\end{itemize}

\begin{figure}[H]
        \centering
        \begin{subfigure}[b]{0.48\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/design_pattern/qpt_filter_customers.pdf}
            \caption{Domain tree for $filter_1$ QPU in Figure~\ref{fig:qpu_graph_emergent_properties}.}
            \label{fig:qpt_filter_customers}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.48\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/design_pattern/qpt_filter_orders.pdf}
  \caption{Domain tree for $filter_2$ QPU in Figure~\ref{fig:qpu_graph_emergent_properties}.}
  \label{fig:qpt_filter_orders}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/design_pattern/qpt_join.pdf}
            \caption{Domain tree for $join$ QPU in Figure~\ref{fig:qpu_graph_emergent_properties}.}
            \label{fig:qpt_join}
        \end{subfigure}
        \caption{Domain trees for the QPU graph in Figure~\ref{fig:qpu_graph_emergent_properties}.}
    \end{figure}

% \begin{figure}[H]
%   \centering
%     \includegraphics[width=\textwidth]{./figures/design_pattern/qpt_corpus_driver_customers.pdf}
%   \caption{Query processing tree for $corpus$ $driver_1$}
%   \label{fig:qpt_corpus_driver_customers}
% \end{figure}

% \begin{figure}[H]
%   \centering
%     \includegraphics[width=\textwidth]{./figures/design_pattern/qpt_corpus_driver_orders.pdf}
%   \caption{Query processing tree for $corpus$ $driver_2$}
%   \label{fig:qpt_corpus_driver_orders}
% \end{figure}

% \begin{figure}[H]
%   \centering
%   \includegraphics[width=\textwidth]{./figures/design_pattern/qpt_filter_customers.pdf}
%   \caption{Query processing tree $filter_1$}
%   \label{fig:qpt_filter_customers}
% \end{figure}

% \begin{figure}[H]
%   \centering
%   \includegraphics[width=\textwidth]{./figures/design_pattern/qpt_filter_orders.pdf}
%   \caption{Query processing tree for $filter_2$}
%   \label{fig:qpt_filter_orders}
% \end{figure}

% \begin{figure}[H]
%   \centering
%   \includegraphics[width=\textwidth]{./figures/design_pattern/qpt_join.pdf}
%   \caption{Query processing tree for $join$}
%   \label{fig:qpt_join}
% \end{figure}

QPU trees have two functionalities:
\begin{itemize}
  \item A query processing unit uses its own domain tree in order to determine whether it can process a given query.
  More specifically, it checks if the query's parse is a subtree of the QPU's domain tree,
  and, therefore, if the query's parse tree belongs in the set of queries represented by the QPU tree
  (algorithm~\ref{algo:can_process_query}).

  \item A query processing unit uses the domain trees of its downstream connections in order to generate downstream queries.
  Given a query $q$ with parse tree $PT_q$, received a query processing unit $Q$ that has a downstream connections $Q_d$
  with domain tree $DCT_{Qd}$, the parse tree of the downstream query to be sent from $Q$ to $Q_d$ for $q$ is the
  \textbf{intersection} of $DT_{Qd}$ and $PT_q$
  (algorithm~\ref{algo:generate_downsrream}).
\end{itemize}

\begin{algorithm}
\caption{Algorithm for check if a query can be processed}
\label{algo:can_process_query}
\begin{algorithmic}
\Function{CanProcessQuery}{queryReq, DomainTree}
\State queryParseTree = parse queryReq
\State \Return {isSubTree(DomainTree, queryReq)}
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Algorithm for generating downstream queries}
\label{algo:generate_downsrream}
\begin{algorithmic}
\Function{GenerateDownstreamQuery}{queryReq, downstreamConn}
\State queryParseTree = parse queryReq
\State domainTree = get domain tree of downstreamConn
\State downStreamQueryParseTree = intersection(domainTree, queryParseTree)
\State downStreamQueryReq = generate query from parse tree
\State \Return downStreamQueryReq
\EndFunction
\end{algorithmic}
\end{algorithm}

% \subsubsection{Ordering guarantees}

% Providing ordering guarantees is based on two mechanisms:
% For a given query $q$:
% \begin{itemize}
%   \item Leaf nodes (corpus driver and derived state classes) generate ordered output streams,
%   based on the ordering specified by $q$.

%   \item Relational operator classes ensure that they \textit{preserve} the ordering of
%   their input stream at their output stream.
% \end{itemize}

% //// Outline ////

% Illustrate using example:
% {\obeylines\obeyspaces
% \texttt{
%         SELECT OrderID, OrderStatus, Email, OrderDate
%         FROM Customers JOIN Orders ON Customers.CustomerID = Orders.CustomerID
%         WHERE OrderStatus = "Processing"
%         TIMESTAMP FROM LATEST TO LATEST
%         ORDER BY OrderDate
%         }}

% \begin{itemize}
%   \item Corpus driver for Orders Table generates output stream ordered by OrderDate
%   \item Filter table keeps only records for which OrderStatus = ``Processing''; this preserves order
%   \item Join uses input from Orders table as ``ordering guide''; this ensures that output is ordered by
%   by OrderDate
% \end{itemize}

% \medskip
% \noindent
% More details on how QPUs preserve ordering semantics:
% \begin{itemize}
%   \item Trivial for QPU's with one input stream
%   \item For QPUs that merge more than one input streams (for example a partition manager), since each input stream
%   is ordered, the ``mergesort'' approach can be used.
%   \item Joins can preserve ordering by using the ``ordered'' input stream as a guide.
%   \item Aggregators (TODO)
% \end{itemize}

% //// Outline ////

\section{Discussion}

\subsection{QPU-based query processing systems and ad-hoc queries}.

The goal of the QPU-based design pattern is to enable \textit{workload-driven design}.
A QPU graph is designed based a predefined set of query patterns.
As a result, a QPU graph does not support any ad-hoc query,
but rather \textit{the set of queries it has been designed for}.
More specifically, as described in section~\ref{sec:qpc_tree}, a QPU graph supports the set of queries represent by the domain trees of its root nodes.
Supporting additional query patterns, not supported by a certain QPU graph requires designing and deploying a
new QPU graph.


\subsection{Query processing unit consistency semantics}

The query engine architecture presented maintains derived state, including indexes and materialized views,
in a system that is separate to the data storage tier.
This creates two considerations about the consistency of query results:
the consistency between base data and derived state,
and the consistency between different indexes or materialized views, or shards of an index/view,
maintained by the query engines.
We discuss former in this section, and outline the latter as a direction for future work (\S\ref{sec:future_consistent_snapshots}).

We refer to a stateful QPU as \textit{internally consistent} in time $t$,
if its state has been updated according to all updates with timestamp $\leq$ $t$, and no updates with timestamp $>$ $t$.
Our design ensures that 1) if a query $q$ with a timestamp $t_q$ is issued to a stateful QPU $Q$,
and $Q$ has received and processed an update with timestamp $\geq$ $t_q$,
then $Q$ can evaluate $q$ on an internally consistent snapshot of its state with timestamp $t_q$,
and 2) any $Q$ can evaluate any subsequent query on an internally consistent snapshot of its state with timestamp $\geq$ $t_q$.
Essentially, this property ensures that any state snapshot of a stateful QPU reflects a (potentially stale) snapshot
of the corpus data.

The query processing unit design achieves that as follows:
\begin{itemize}
  \item We assume that updates the data storage tier propagates updates to the QPU graph in-order, according to their timestamps.

  \item The stream connection between two QPUs ensures that streams records are not lost or re-ordered.

  \item Given a stream of input records with increasing timestamps,
  relational operator QPUs emits result records that also have increasing timestamps (potentially a subset of the input timestamps).
\end{itemize}

\section{Conclusion}
This chapter presented the design of a modular and composable query engine architecture.
It introduced the Query Processing Unit, presented its specification,
and described how it can be used as a building block for constructing query engine architectures.

% Given $q$, the query processing function of a QPU $Q$ at the root of the QPU graph sends query request to some its
% downstream connection, in order to initialize input stream required for processing the query.
% Upon receiving a query request from $Q$, each of its downstream connection performs the same process.
% In that way, query requests are propagated downwards through the QPU graph, creating a \textit{query execution sub-graph}
% composed of the QPUs that participate in the processing of $q$.

% As query requests requests are propagated downwards, expanding the $q$'s execution sub-graph, eventually some QPUs can
% process their queries without sending further query requests downwards.
% This occurs in corpus driver and derived state QPUs.
% The leaves of this sub-graph are QPU that can process 
% This includes corpus driver QPUs, and derived state QPUs.
% These QPUs produce output streams that are then processed as input stream at \textit{upstream QPUs}.

% Progressively, each non-leaf QPU in the query sub-graph receives an input stream for each query request sent,
% and produces it self an output 


% We describe how a QPU graph processes a given query using the example of Figure~\ref{fig:qpu_graph_emergent_properties}.

% Consider the query:
% {\obeylines\obeyspaces
% \texttt{Q = SELECT CustomerName, CustomerEmail, OrderID
%         ~~~~FROM Customers
%         ~~~~INNER JOIN Orders ON Customers.OrderID = Orders.OrderID
%         ~~~~WHERE Orders.OrderDate >= 2020-08-20 AND Orders.OrderDate < 2020-09-02
%         ~~~~TIMESTAMP FROM LATEST TO LATEST
%         }}

% - queries / control messages flow downwards.
% - responses flow upwards through the sub-graph defined by the queries
% - (each query establishes a sub-graph - actually a tree - to be used by that particular query);
% - Updates (independently) also flow upwards

% As described in the previous sections, query processing units can collaborate by invoking the query API of one another.
% QPUs can be composed in DAG hierarchies in which parent units can invoke the query API of their child units.
% Query responses for both snapshot and persistent queries are streams of results.
% Communication between QPUs thus uses a combination of the remote procedural call model (query API invocations) and the stream-processing model (query responses).

% Clients perform queries by invoking the query API of units at root nodes of the graph.
% Once a QPU receives a query, it determines whether it can directly process it, for example by performing lookups at its indexing structures,
% and if that is the case it responds with the query result.
% In case the query processing computation requires partial query results from its child units, the unit invokes the query API of those units with the appropriate sub-queries.
% Sub-query results are received and processed through the unit's callback function.

% This process is recursively performed at each query processing unit.

% Therefore, the computation that runs in QPU a graph can be modeled as a bidirectional data-flow computation.
% Queries flow downwards through the graph, are incrementally split into sub-queries, and processed across the graph.
% Sub-query results flow back upwards, are incrementally processed, and eventually produce the results to the initial query.

% The same computation model is used for index maintenance.
% We have extended the query interface semantics so that the query API can be used to subscribe to notifications for corpus updates, and query results can encode these updates.
% Using this mechanism, units with indexing functionalities can subscribe to corpus updates by invoking the query API of QPUs that provide this functionality.
% We describe this mechanism in more detail in Section \ref{subsec:query_classes}.


% The QPU graph runs a distributed bidirectional data-flow computation.

% A client performs a query $Q_c$ by invoking the query API of a query processing unit at the root of the graph.
% As described in Section~\ref{subsec:qpu}, the QPUs query processing computation can read from the unit's state,
% or perform downstream queries to QPUs at its child nodes.

% When a downstream query is performed, this process is recursively executed at each unit whose query API is invoked.
% Though this mechanism, $Q_c$ is incrementally transformed to sub-queries which flow downwards through the QPU graph,
% invoking computations at different nodes.
% Sub-query results are returned through the QPU streams established from query API invocations, and flow upwards
% through the graph.
% These results are incrementally processed, potentially updating the state of different QPUs, and eventually
% produce the initial query results, which are returned to the client.

% \section{QPU Composition: Constructing QPU-based query engines}
% Here, describe how query engines are constructed using instances of QPU classes.

% A query engine is a directed acyclic graph (why?) with QPUs as nodes.

% Describe the QPU-specific topology properties that the graph must satisfy in
% order to be functional:
% \begin{itemize}
%   \item All leaves must be QPUs of the datastore driver class.
%   Also, datastore driver QPUs cannot be nodes other than leaves.
%   \item TODO
% \end{itemize}

% \section{Computation Model}
% Describe the bidirectional data-flow computation.
% \begin{itemize}
%   \item Control messages (queries) flow downwards.
%   \item Responses flow upwards through the sub-graph defined by the control
%   (each query establishes a sub-graph - actually a tree - to be used by that
%   particular query);
%   \item Updates (independently) also flow upwards.
% \end{itemize}


% % \section{The consistency guarantees of QPU-based query engines}
% % TODO: What mechanism are needed so that QPUs can guarantee internal consistency?
% % What about session consistency guarantees?



% % It is known that query execution can be represented as a tree.
% % Base data are at the tree's leaves, tree nodes are relational operator such
% % as filter, joins and aggregations, and query result are at the root of the tree.
% % Each operator receives an input stream of records, performs a transformation on the, and emits a output stream of record.
% % This results to a data-flow computation in which data items flow upwards through the tree and are progressively transformed
% % to the query execution results.

% % Computation tasks vs architecture components

% % Our approach is based on three simple insights:
% % \begin{itemize}
% %     \item \textbf{Index-based distributed query processing is composed of basic, primitive tasks.}
% %     The most simple query engine design is a component that scans the corpus dataset and selects the data items which match a given query.
% %     When queries for certain attributes are frequent or require low response time, secondary indexes can be materialized for those attributes.
% %     Even when indexes are partitioned and distributed across the system for scalability, the basic components of an indexing system remains the same: index data structures that collaborate through appropriate index maintenance and query processing protocols to implement distributed indexes.
% %     Additional query processing functionalities such as multi-attribute queries, joins or federated queries across multiple corpus can be implemented using operators that build on top of these components.
% %     Finally, caching can be used to further improve response time for certain queries.

% %     \item \textbf{Primitive query processing tasks can be encapsulated by a common query processing component model.}
% %     Each of the described tasks can be encapsulated by a query processing component model with two properties: an API for responding to queries, and a callback function.
% %     For example, index data structures in general implement three basic functions: LOOKUP, INSERT, DELETE.
% %     The query API can encapsulate the LOOKUP function, while the callback function can express the task of index maintenance, receiving corpus updates and updating the index accordingly, and therefore encapsulate INSERT and DELETE.
% %     As another example, a cache on top of an index structure should be able to respond to the same queries as the underlying index, and therefore can be encapsulated by a query processing component with the same query API.
% %     Similarly, its callback function can express the task of receiving query results in case of a cache miss, and updating the cache.
% %     This concept can be generalized to represent other query processing components including bloom filters, materialized views, and streaming operators.

% %     \item \textbf{Query processing components need to cooperate to implement complex query processing tasks.}
% %     As an example, a caching component requires the ability to forward queries to other components, such as indexes, when cache misses occur.
% %     Similarly, a distributed indexing system, in which indexes are partitioned and distributed across system nodes, can be implemented using indexing components with the help of an additional component responsible for implementing a partitioned LOOKUP operation, by collecting and aggregating partial LOOKUP results.
% % \end{itemize}

% % Based on these observations, we introduce a query processing component model, called the \textit{Query Processing Unit} (QPU).
% % We have designed a generic query API and callback function interface with the aim of encapsulating multiple different query processing components.
% % Query processing units may have internal state for facilitating query processing, or be stateless.
% % Additionally, QPUs have the ability to invoke the query API of one another, and thus interoperate for query processing.