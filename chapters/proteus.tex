The goal of this chapter is to present Proteus, a framework for facilitating
the construction and deployment of QPU-based query processing systems.

This includes:
\begin{itemize}
  \item Presenting the library of QPU implementations offered by Proteus.
  \item Describing the additional mechanism offered by Proteus for deploying and
  connecting.
  \item Reporting on subjects including rules of QPU composition (incompatible
  topologies), (steps towards automatic cost-model based deployment plans for
  QPU graphs)*, and implementation details.
\end{itemize}

Having presented the QPU characteristics, the principle of composing QPUs in a DAG, and the graph's computation model,
the goal of this chapter is to concretely.

\section{QPU query processing capabilities}

Each QPU is responsible/capable of processing queries in a specific space. These capabilities depend on:
\begin{itemize}
  \item The QPU's functionality (class).
  \item It's configuration.
  \item It's child connections in the graph.
\end{itemize}

QPUs maintain metadata (state) that describe their own capabilities, as well as their knowledge of the capabilities of
their child connections.

In this section we describe the format of the query processing capabilities state. We defer the description of how QPUs
populate this state for the following section.

\section{Distributed query processing protocol}
In this section we present the protocol that QPUs use to retrieve intermediate query responses for a given query by
sending sub-queries to child QPUs.

In detail, we present the algorithms for:
\begin{itemize}
  \item Determining if the QPU can process a given query locally, or if the QPU needs to forward parts of the query
  processing computation to the QPU graph.
  This can be done by sending sub-queries to its child connections.
  \item How a QPU uses its knowledge of the query processing capabilities of its child connections to generate and send
  sub-queries.
\end{itemize}

This protocol runs locally at each QPU and requires no central coordination.

\section{Configuration Dissemination}
In this section we describe how QPUs build/populate the query processing capabilities state.

Overview:
\begin{itemize}
  \item In the case of the index QPU, its configuration explicitly describes which queries can be processed locally
  (using the index).
  \item For other QPUs (e.g. filter, cache), their capabilities depend on the capabilities of their child connections.
  For example, if a cache QPU is connected to an index QPU, it inherits the query capabilities of that QPU.
\end{itemize}

Here, we also define the operation of combining the capabilities of more than one QPUs (a QPU uses that operation to
calculate its capabilities given its configuration and the capabilities of its children)

% \subsection{Configuration propagation API}
% Νο 5.3.2

\section{QPU Library}
Describe the implementation-specific details, assumptions, and limitations of
the QPU classes provided by Proteus.

\subsection{Datastore driver}
\subsubsection{Backend data stores}

\subsection{Filter}

\subsection{Index}

\subsection{Cache}

\subsection{Multiplex \ De-Multiplex}

\subsection{Conjunction / Disjunction}


\section{Constructing QPU-based query engines}
Demonstrate the use of the QPU classes described above for constructing query
engines.

\subsection{QPU graph topology rules}
Summarize the rules that apply to the construction of QPU graphs.
This includes:
\begin{itemize}
  \item Components (caches, filters) that do not have multiplexing logic and can
  only be put on top of one QPU.
  \item How the QPU graph is connected with the data storage tier via data store
  driver QPUs.
\end{itemize}

In this chapter, include rules that are not inherent to the QPU design, but
rather are due to the implementation choices.

Rules that are inherent to all QPU graphs, should be stated in
% Chapter~\ref{ch:design_pattern}.


\subsection{Reference QPU architecture patterns}
Demonstrate in detail how Proteus can be used to build a number of query engine
architectures.

Reference architectures can be categorized by two characteristics: (1) the query
processing components they use (filter-only, filter-and-cache, index-base, ..),
and (2) the storage tier architecture they target (single database instance,
sharded database, replication, federation)

For (2) we will take a ``zooming out'' approach: each reference architecture
building on top of the previous one.

\subsubsection{Partitioned index}

\section{Fault tolerance}
Describe the mechanisms provided by Proteus for tolerating faults during query
processing.
\begin{itemize}
  \item Lost or re-ordered stream records.
  \item Mid-query QPU crash.
  \item Partitions.
\end{itemize}

\section{Implementation}
Report on the implementation of different components of Proteus, including:
\begin{itemize}
  \item The framework used for communication between QPUs.
  \item How streams are implemented.
  \item ...
\end{itemize}
